{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "credxo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rhnd85yE9b4",
        "colab_type": "text"
      },
      "source": [
        "##Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJfhjOpJc5Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA \n",
        "import numpy as np\n",
        "from keras.layers import Input,concatenate,LSTM,Dense\n",
        "from keras.models import Model\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op7zJPTcFE4G",
        "colab_type": "text"
      },
      "source": [
        "##Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkiD7rAyc5Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(\"musk_csv.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndmRX5QMc5W7",
        "colab_type": "code",
        "outputId": "5c85902c-5311-414d-9567-d90c98e847a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6598, 170)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VR7_0RRc5XQ",
        "colab_type": "code",
        "outputId": "af5ee597-f01d-4d9f-ab56-890e4424ecdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>molecule_name</th>\n",
              "      <th>conformation_name</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>...</th>\n",
              "      <th>f128</th>\n",
              "      <th>f129</th>\n",
              "      <th>f130</th>\n",
              "      <th>f131</th>\n",
              "      <th>f132</th>\n",
              "      <th>f133</th>\n",
              "      <th>f134</th>\n",
              "      <th>f135</th>\n",
              "      <th>f136</th>\n",
              "      <th>f137</th>\n",
              "      <th>f138</th>\n",
              "      <th>f139</th>\n",
              "      <th>f140</th>\n",
              "      <th>f141</th>\n",
              "      <th>f142</th>\n",
              "      <th>f143</th>\n",
              "      <th>f144</th>\n",
              "      <th>f145</th>\n",
              "      <th>f146</th>\n",
              "      <th>f147</th>\n",
              "      <th>f148</th>\n",
              "      <th>f149</th>\n",
              "      <th>f150</th>\n",
              "      <th>f151</th>\n",
              "      <th>f152</th>\n",
              "      <th>f153</th>\n",
              "      <th>f154</th>\n",
              "      <th>f155</th>\n",
              "      <th>f156</th>\n",
              "      <th>f157</th>\n",
              "      <th>f158</th>\n",
              "      <th>f159</th>\n",
              "      <th>f160</th>\n",
              "      <th>f161</th>\n",
              "      <th>f162</th>\n",
              "      <th>f163</th>\n",
              "      <th>f164</th>\n",
              "      <th>f165</th>\n",
              "      <th>f166</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>MUSK-211</td>\n",
              "      <td>211_1+1</td>\n",
              "      <td>46</td>\n",
              "      <td>-108</td>\n",
              "      <td>-60</td>\n",
              "      <td>-69</td>\n",
              "      <td>-117</td>\n",
              "      <td>49</td>\n",
              "      <td>38</td>\n",
              "      <td>-161</td>\n",
              "      <td>-8</td>\n",
              "      <td>5</td>\n",
              "      <td>-323</td>\n",
              "      <td>-220</td>\n",
              "      <td>-113</td>\n",
              "      <td>-299</td>\n",
              "      <td>-283</td>\n",
              "      <td>-307</td>\n",
              "      <td>-31</td>\n",
              "      <td>-106</td>\n",
              "      <td>-227</td>\n",
              "      <td>-42</td>\n",
              "      <td>-59</td>\n",
              "      <td>-22</td>\n",
              "      <td>-67</td>\n",
              "      <td>189</td>\n",
              "      <td>81</td>\n",
              "      <td>17</td>\n",
              "      <td>-27</td>\n",
              "      <td>-89</td>\n",
              "      <td>-67</td>\n",
              "      <td>105</td>\n",
              "      <td>-116</td>\n",
              "      <td>124</td>\n",
              "      <td>-106</td>\n",
              "      <td>5</td>\n",
              "      <td>-120</td>\n",
              "      <td>63</td>\n",
              "      <td>-165</td>\n",
              "      <td>...</td>\n",
              "      <td>81</td>\n",
              "      <td>-114</td>\n",
              "      <td>-187</td>\n",
              "      <td>45</td>\n",
              "      <td>-118</td>\n",
              "      <td>-75</td>\n",
              "      <td>-182</td>\n",
              "      <td>-234</td>\n",
              "      <td>-19</td>\n",
              "      <td>12</td>\n",
              "      <td>-13</td>\n",
              "      <td>-41</td>\n",
              "      <td>-119</td>\n",
              "      <td>-149</td>\n",
              "      <td>70</td>\n",
              "      <td>17</td>\n",
              "      <td>-20</td>\n",
              "      <td>-177</td>\n",
              "      <td>-101</td>\n",
              "      <td>-116</td>\n",
              "      <td>-14</td>\n",
              "      <td>-50</td>\n",
              "      <td>24</td>\n",
              "      <td>-81</td>\n",
              "      <td>-125</td>\n",
              "      <td>-114</td>\n",
              "      <td>-44</td>\n",
              "      <td>128</td>\n",
              "      <td>3</td>\n",
              "      <td>-244</td>\n",
              "      <td>-308</td>\n",
              "      <td>52</td>\n",
              "      <td>-7</td>\n",
              "      <td>39</td>\n",
              "      <td>126</td>\n",
              "      <td>156</td>\n",
              "      <td>-50</td>\n",
              "      <td>-112</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>MUSK-211</td>\n",
              "      <td>211_1+10</td>\n",
              "      <td>41</td>\n",
              "      <td>-188</td>\n",
              "      <td>-145</td>\n",
              "      <td>22</td>\n",
              "      <td>-117</td>\n",
              "      <td>-6</td>\n",
              "      <td>57</td>\n",
              "      <td>-171</td>\n",
              "      <td>-39</td>\n",
              "      <td>-100</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-228</td>\n",
              "      <td>-281</td>\n",
              "      <td>-281</td>\n",
              "      <td>-300</td>\n",
              "      <td>54</td>\n",
              "      <td>-149</td>\n",
              "      <td>-98</td>\n",
              "      <td>-196</td>\n",
              "      <td>-27</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>75</td>\n",
              "      <td>49</td>\n",
              "      <td>-34</td>\n",
              "      <td>45</td>\n",
              "      <td>-91</td>\n",
              "      <td>32</td>\n",
              "      <td>95</td>\n",
              "      <td>-116</td>\n",
              "      <td>85</td>\n",
              "      <td>-23</td>\n",
              "      <td>42</td>\n",
              "      <td>-58</td>\n",
              "      <td>61</td>\n",
              "      <td>-171</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>-21</td>\n",
              "      <td>-32</td>\n",
              "      <td>32</td>\n",
              "      <td>-128</td>\n",
              "      <td>-72</td>\n",
              "      <td>-124</td>\n",
              "      <td>-218</td>\n",
              "      <td>-94</td>\n",
              "      <td>53</td>\n",
              "      <td>-79</td>\n",
              "      <td>-20</td>\n",
              "      <td>-35</td>\n",
              "      <td>-26</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-102</td>\n",
              "      <td>-121</td>\n",
              "      <td>-66</td>\n",
              "      <td>-77</td>\n",
              "      <td>51</td>\n",
              "      <td>-41</td>\n",
              "      <td>-34</td>\n",
              "      <td>-32</td>\n",
              "      <td>-63</td>\n",
              "      <td>115</td>\n",
              "      <td>-5</td>\n",
              "      <td>-235</td>\n",
              "      <td>-59</td>\n",
              "      <td>-2</td>\n",
              "      <td>52</td>\n",
              "      <td>103</td>\n",
              "      <td>136</td>\n",
              "      <td>169</td>\n",
              "      <td>-61</td>\n",
              "      <td>-136</td>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>MUSK-211</td>\n",
              "      <td>211_1+11</td>\n",
              "      <td>46</td>\n",
              "      <td>-194</td>\n",
              "      <td>-145</td>\n",
              "      <td>28</td>\n",
              "      <td>-117</td>\n",
              "      <td>73</td>\n",
              "      <td>57</td>\n",
              "      <td>-168</td>\n",
              "      <td>-39</td>\n",
              "      <td>-22</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-104</td>\n",
              "      <td>-283</td>\n",
              "      <td>-282</td>\n",
              "      <td>-303</td>\n",
              "      <td>52</td>\n",
              "      <td>-152</td>\n",
              "      <td>-97</td>\n",
              "      <td>-225</td>\n",
              "      <td>-28</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>179</td>\n",
              "      <td>49</td>\n",
              "      <td>-33</td>\n",
              "      <td>46</td>\n",
              "      <td>-88</td>\n",
              "      <td>22</td>\n",
              "      <td>79</td>\n",
              "      <td>-116</td>\n",
              "      <td>19</td>\n",
              "      <td>-11</td>\n",
              "      <td>6</td>\n",
              "      <td>-38</td>\n",
              "      <td>71</td>\n",
              "      <td>-175</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>-23</td>\n",
              "      <td>-15</td>\n",
              "      <td>-129</td>\n",
              "      <td>-74</td>\n",
              "      <td>-125</td>\n",
              "      <td>-221</td>\n",
              "      <td>-93</td>\n",
              "      <td>53</td>\n",
              "      <td>-72</td>\n",
              "      <td>-19</td>\n",
              "      <td>-33</td>\n",
              "      <td>-26</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-102</td>\n",
              "      <td>-119</td>\n",
              "      <td>-66</td>\n",
              "      <td>-81</td>\n",
              "      <td>51</td>\n",
              "      <td>-41</td>\n",
              "      <td>-27</td>\n",
              "      <td>-41</td>\n",
              "      <td>-140</td>\n",
              "      <td>77</td>\n",
              "      <td>-163</td>\n",
              "      <td>-238</td>\n",
              "      <td>-134</td>\n",
              "      <td>-154</td>\n",
              "      <td>57</td>\n",
              "      <td>143</td>\n",
              "      <td>142</td>\n",
              "      <td>165</td>\n",
              "      <td>-67</td>\n",
              "      <td>-145</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>MUSK-211</td>\n",
              "      <td>211_1+12</td>\n",
              "      <td>41</td>\n",
              "      <td>-188</td>\n",
              "      <td>-145</td>\n",
              "      <td>22</td>\n",
              "      <td>-117</td>\n",
              "      <td>-7</td>\n",
              "      <td>57</td>\n",
              "      <td>-170</td>\n",
              "      <td>-39</td>\n",
              "      <td>-99</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-228</td>\n",
              "      <td>-282</td>\n",
              "      <td>-281</td>\n",
              "      <td>-301</td>\n",
              "      <td>54</td>\n",
              "      <td>-150</td>\n",
              "      <td>-98</td>\n",
              "      <td>-196</td>\n",
              "      <td>-28</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>77</td>\n",
              "      <td>48</td>\n",
              "      <td>-34</td>\n",
              "      <td>46</td>\n",
              "      <td>-91</td>\n",
              "      <td>32</td>\n",
              "      <td>94</td>\n",
              "      <td>-116</td>\n",
              "      <td>84</td>\n",
              "      <td>-23</td>\n",
              "      <td>41</td>\n",
              "      <td>-58</td>\n",
              "      <td>62</td>\n",
              "      <td>-171</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>-20</td>\n",
              "      <td>-32</td>\n",
              "      <td>32</td>\n",
              "      <td>-128</td>\n",
              "      <td>-73</td>\n",
              "      <td>-125</td>\n",
              "      <td>-220</td>\n",
              "      <td>-93</td>\n",
              "      <td>53</td>\n",
              "      <td>-78</td>\n",
              "      <td>-19</td>\n",
              "      <td>-34</td>\n",
              "      <td>-26</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-101</td>\n",
              "      <td>-121</td>\n",
              "      <td>-65</td>\n",
              "      <td>-77</td>\n",
              "      <td>52</td>\n",
              "      <td>-41</td>\n",
              "      <td>-34</td>\n",
              "      <td>-32</td>\n",
              "      <td>-66</td>\n",
              "      <td>115</td>\n",
              "      <td>-7</td>\n",
              "      <td>-236</td>\n",
              "      <td>-60</td>\n",
              "      <td>-4</td>\n",
              "      <td>52</td>\n",
              "      <td>104</td>\n",
              "      <td>136</td>\n",
              "      <td>168</td>\n",
              "      <td>-60</td>\n",
              "      <td>-135</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>MUSK-211</td>\n",
              "      <td>211_1+13</td>\n",
              "      <td>41</td>\n",
              "      <td>-188</td>\n",
              "      <td>-145</td>\n",
              "      <td>22</td>\n",
              "      <td>-117</td>\n",
              "      <td>-7</td>\n",
              "      <td>57</td>\n",
              "      <td>-170</td>\n",
              "      <td>-39</td>\n",
              "      <td>-99</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-228</td>\n",
              "      <td>-282</td>\n",
              "      <td>-281</td>\n",
              "      <td>-301</td>\n",
              "      <td>54</td>\n",
              "      <td>-150</td>\n",
              "      <td>-98</td>\n",
              "      <td>-196</td>\n",
              "      <td>-28</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>78</td>\n",
              "      <td>48</td>\n",
              "      <td>-34</td>\n",
              "      <td>46</td>\n",
              "      <td>-91</td>\n",
              "      <td>31</td>\n",
              "      <td>94</td>\n",
              "      <td>-116</td>\n",
              "      <td>84</td>\n",
              "      <td>-23</td>\n",
              "      <td>41</td>\n",
              "      <td>-58</td>\n",
              "      <td>62</td>\n",
              "      <td>-171</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>-20</td>\n",
              "      <td>-32</td>\n",
              "      <td>32</td>\n",
              "      <td>-128</td>\n",
              "      <td>-73</td>\n",
              "      <td>-125</td>\n",
              "      <td>-220</td>\n",
              "      <td>-93</td>\n",
              "      <td>53</td>\n",
              "      <td>-78</td>\n",
              "      <td>-19</td>\n",
              "      <td>-34</td>\n",
              "      <td>-26</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-101</td>\n",
              "      <td>-121</td>\n",
              "      <td>-65</td>\n",
              "      <td>-76</td>\n",
              "      <td>52</td>\n",
              "      <td>-41</td>\n",
              "      <td>-34</td>\n",
              "      <td>-32</td>\n",
              "      <td>-66</td>\n",
              "      <td>115</td>\n",
              "      <td>-8</td>\n",
              "      <td>-236</td>\n",
              "      <td>-60</td>\n",
              "      <td>-4</td>\n",
              "      <td>52</td>\n",
              "      <td>104</td>\n",
              "      <td>137</td>\n",
              "      <td>168</td>\n",
              "      <td>-60</td>\n",
              "      <td>-135</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 170 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID molecule_name conformation_name  f1   f2  ...  f163  f164  f165  f166  class\n",
              "0   1      MUSK-211           211_1+1  46 -108  ...   156   -50  -112    96      1\n",
              "1   2      MUSK-211          211_1+10  41 -188  ...   169   -61  -136    79      1\n",
              "2   3      MUSK-211          211_1+11  46 -194  ...   165   -67  -145    39      1\n",
              "3   4      MUSK-211          211_1+12  41 -188  ...   168   -60  -135    80      1\n",
              "4   5      MUSK-211          211_1+13  41 -188  ...   168   -60  -135    80      1\n",
              "\n",
              "[5 rows x 170 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izFU8IwSFREC",
        "colab_type": "text"
      },
      "source": [
        "### Unique Class in Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKyaXKI7c5Xa",
        "colab_type": "code",
        "outputId": "435f64bc-542f-4146-f784-98fa8a17b046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data[\"class\"].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMeUN9Skc5Xi",
        "colab_type": "code",
        "outputId": "261603c7-4d28-4a71-bbaa-adb7531521ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                    int64\n",
              "molecule_name        object\n",
              "conformation_name    object\n",
              "f1                    int64\n",
              "f2                    int64\n",
              "                      ...  \n",
              "f163                  int64\n",
              "f164                  int64\n",
              "f165                  int64\n",
              "f166                  int64\n",
              "class                 int64\n",
              "Length: 170, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-_bI_jc5Xt",
        "colab_type": "code",
        "outputId": "fa83848f-6c7c-457c-b7ec-8fe5ffc96dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>f39</th>\n",
              "      <th>...</th>\n",
              "      <th>f128</th>\n",
              "      <th>f129</th>\n",
              "      <th>f130</th>\n",
              "      <th>f131</th>\n",
              "      <th>f132</th>\n",
              "      <th>f133</th>\n",
              "      <th>f134</th>\n",
              "      <th>f135</th>\n",
              "      <th>f136</th>\n",
              "      <th>f137</th>\n",
              "      <th>f138</th>\n",
              "      <th>f139</th>\n",
              "      <th>f140</th>\n",
              "      <th>f141</th>\n",
              "      <th>f142</th>\n",
              "      <th>f143</th>\n",
              "      <th>f144</th>\n",
              "      <th>f145</th>\n",
              "      <th>f146</th>\n",
              "      <th>f147</th>\n",
              "      <th>f148</th>\n",
              "      <th>f149</th>\n",
              "      <th>f150</th>\n",
              "      <th>f151</th>\n",
              "      <th>f152</th>\n",
              "      <th>f153</th>\n",
              "      <th>f154</th>\n",
              "      <th>f155</th>\n",
              "      <th>f156</th>\n",
              "      <th>f157</th>\n",
              "      <th>f158</th>\n",
              "      <th>f159</th>\n",
              "      <th>f160</th>\n",
              "      <th>f161</th>\n",
              "      <th>f162</th>\n",
              "      <th>f163</th>\n",
              "      <th>f164</th>\n",
              "      <th>f165</th>\n",
              "      <th>f166</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6598.00000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "      <td>6598.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3299.50000</td>\n",
              "      <td>58.945135</td>\n",
              "      <td>-119.128524</td>\n",
              "      <td>-73.146560</td>\n",
              "      <td>-0.628372</td>\n",
              "      <td>-103.533495</td>\n",
              "      <td>18.359806</td>\n",
              "      <td>-14.108821</td>\n",
              "      <td>-1.858290</td>\n",
              "      <td>-86.003031</td>\n",
              "      <td>-44.495756</td>\n",
              "      <td>-119.456502</td>\n",
              "      <td>-84.929221</td>\n",
              "      <td>-61.911185</td>\n",
              "      <td>-127.935283</td>\n",
              "      <td>-123.005153</td>\n",
              "      <td>-265.690967</td>\n",
              "      <td>-53.415732</td>\n",
              "      <td>-67.741285</td>\n",
              "      <td>-52.352531</td>\n",
              "      <td>-44.902698</td>\n",
              "      <td>-75.645953</td>\n",
              "      <td>-55.783419</td>\n",
              "      <td>-61.619127</td>\n",
              "      <td>72.506062</td>\n",
              "      <td>32.285238</td>\n",
              "      <td>-69.659139</td>\n",
              "      <td>-15.361018</td>\n",
              "      <td>-102.665959</td>\n",
              "      <td>8.520764</td>\n",
              "      <td>12.553956</td>\n",
              "      <td>-82.314186</td>\n",
              "      <td>25.436193</td>\n",
              "      <td>-34.503183</td>\n",
              "      <td>-78.915732</td>\n",
              "      <td>-73.199000</td>\n",
              "      <td>115.882995</td>\n",
              "      <td>-115.562746</td>\n",
              "      <td>-7.853289</td>\n",
              "      <td>-75.578509</td>\n",
              "      <td>...</td>\n",
              "      <td>-19.476811</td>\n",
              "      <td>-68.070627</td>\n",
              "      <td>-94.963474</td>\n",
              "      <td>2.993786</td>\n",
              "      <td>-36.652774</td>\n",
              "      <td>-79.191422</td>\n",
              "      <td>-90.778266</td>\n",
              "      <td>-95.868142</td>\n",
              "      <td>-28.259473</td>\n",
              "      <td>-8.521067</td>\n",
              "      <td>-37.599121</td>\n",
              "      <td>-67.789330</td>\n",
              "      <td>-51.976508</td>\n",
              "      <td>-65.693089</td>\n",
              "      <td>-0.443165</td>\n",
              "      <td>1.331464</td>\n",
              "      <td>-21.754319</td>\n",
              "      <td>-165.748863</td>\n",
              "      <td>-87.364050</td>\n",
              "      <td>-113.114580</td>\n",
              "      <td>-18.523644</td>\n",
              "      <td>-41.386481</td>\n",
              "      <td>8.755077</td>\n",
              "      <td>-55.026069</td>\n",
              "      <td>-61.105335</td>\n",
              "      <td>-54.810397</td>\n",
              "      <td>-76.831161</td>\n",
              "      <td>33.209912</td>\n",
              "      <td>-61.212337</td>\n",
              "      <td>-210.975447</td>\n",
              "      <td>-184.798272</td>\n",
              "      <td>-75.795696</td>\n",
              "      <td>-26.073204</td>\n",
              "      <td>64.616702</td>\n",
              "      <td>112.037739</td>\n",
              "      <td>201.760230</td>\n",
              "      <td>-47.488330</td>\n",
              "      <td>-150.259927</td>\n",
              "      <td>41.770233</td>\n",
              "      <td>0.154138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1904.82287</td>\n",
              "      <td>53.249007</td>\n",
              "      <td>90.813375</td>\n",
              "      <td>67.956235</td>\n",
              "      <td>80.444617</td>\n",
              "      <td>64.387559</td>\n",
              "      <td>80.593655</td>\n",
              "      <td>115.315673</td>\n",
              "      <td>90.372537</td>\n",
              "      <td>108.326676</td>\n",
              "      <td>72.088903</td>\n",
              "      <td>108.911397</td>\n",
              "      <td>79.541410</td>\n",
              "      <td>61.444281</td>\n",
              "      <td>101.191126</td>\n",
              "      <td>98.009158</td>\n",
              "      <td>70.647329</td>\n",
              "      <td>117.237608</td>\n",
              "      <td>61.403085</td>\n",
              "      <td>82.503477</td>\n",
              "      <td>79.304489</td>\n",
              "      <td>75.187995</td>\n",
              "      <td>101.908604</td>\n",
              "      <td>94.524709</td>\n",
              "      <td>123.334433</td>\n",
              "      <td>108.105908</td>\n",
              "      <td>101.325550</td>\n",
              "      <td>91.621335</td>\n",
              "      <td>73.778232</td>\n",
              "      <td>63.484770</td>\n",
              "      <td>126.086157</td>\n",
              "      <td>80.225924</td>\n",
              "      <td>106.627993</td>\n",
              "      <td>57.816952</td>\n",
              "      <td>118.201270</td>\n",
              "      <td>75.350809</td>\n",
              "      <td>57.070192</td>\n",
              "      <td>104.682519</td>\n",
              "      <td>85.732778</td>\n",
              "      <td>70.534415</td>\n",
              "      <td>...</td>\n",
              "      <td>130.607205</td>\n",
              "      <td>70.016546</td>\n",
              "      <td>98.100733</td>\n",
              "      <td>60.633027</td>\n",
              "      <td>84.316386</td>\n",
              "      <td>61.733776</td>\n",
              "      <td>68.098995</td>\n",
              "      <td>87.253395</td>\n",
              "      <td>61.664300</td>\n",
              "      <td>97.997434</td>\n",
              "      <td>77.580190</td>\n",
              "      <td>94.753428</td>\n",
              "      <td>64.344336</td>\n",
              "      <td>69.094605</td>\n",
              "      <td>82.410293</td>\n",
              "      <td>103.746483</td>\n",
              "      <td>103.113954</td>\n",
              "      <td>54.087579</td>\n",
              "      <td>51.177725</td>\n",
              "      <td>21.463582</td>\n",
              "      <td>63.048333</td>\n",
              "      <td>73.864481</td>\n",
              "      <td>83.274158</td>\n",
              "      <td>60.100098</td>\n",
              "      <td>70.788743</td>\n",
              "      <td>67.538140</td>\n",
              "      <td>76.908685</td>\n",
              "      <td>98.511502</td>\n",
              "      <td>97.547356</td>\n",
              "      <td>83.710890</td>\n",
              "      <td>107.819514</td>\n",
              "      <td>127.861271</td>\n",
              "      <td>69.727964</td>\n",
              "      <td>100.861935</td>\n",
              "      <td>72.835040</td>\n",
              "      <td>59.526751</td>\n",
              "      <td>55.069365</td>\n",
              "      <td>76.019023</td>\n",
              "      <td>94.116085</td>\n",
              "      <td>0.361108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>-31.000000</td>\n",
              "      <td>-199.000000</td>\n",
              "      <td>-167.000000</td>\n",
              "      <td>-114.000000</td>\n",
              "      <td>-118.000000</td>\n",
              "      <td>-183.000000</td>\n",
              "      <td>-171.000000</td>\n",
              "      <td>-225.000000</td>\n",
              "      <td>-245.000000</td>\n",
              "      <td>-286.000000</td>\n",
              "      <td>-328.000000</td>\n",
              "      <td>-321.000000</td>\n",
              "      <td>-305.000000</td>\n",
              "      <td>-342.000000</td>\n",
              "      <td>-294.000000</td>\n",
              "      <td>-327.000000</td>\n",
              "      <td>-224.000000</td>\n",
              "      <td>-308.000000</td>\n",
              "      <td>-286.000000</td>\n",
              "      <td>-252.000000</td>\n",
              "      <td>-295.000000</td>\n",
              "      <td>-185.000000</td>\n",
              "      <td>-253.000000</td>\n",
              "      <td>-76.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-242.000000</td>\n",
              "      <td>-205.000000</td>\n",
              "      <td>-166.000000</td>\n",
              "      <td>-142.000000</td>\n",
              "      <td>-162.000000</td>\n",
              "      <td>-117.000000</td>\n",
              "      <td>-143.000000</td>\n",
              "      <td>-139.000000</td>\n",
              "      <td>-279.000000</td>\n",
              "      <td>-160.000000</td>\n",
              "      <td>-7.000000</td>\n",
              "      <td>-175.000000</td>\n",
              "      <td>-190.000000</td>\n",
              "      <td>-148.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-221.000000</td>\n",
              "      <td>-307.000000</td>\n",
              "      <td>-189.000000</td>\n",
              "      <td>-123.000000</td>\n",
              "      <td>-140.000000</td>\n",
              "      <td>-319.000000</td>\n",
              "      <td>-338.000000</td>\n",
              "      <td>-336.000000</td>\n",
              "      <td>-196.000000</td>\n",
              "      <td>-197.000000</td>\n",
              "      <td>-199.000000</td>\n",
              "      <td>-243.000000</td>\n",
              "      <td>-283.000000</td>\n",
              "      <td>-290.000000</td>\n",
              "      <td>-185.000000</td>\n",
              "      <td>-157.000000</td>\n",
              "      <td>-171.000000</td>\n",
              "      <td>-179.000000</td>\n",
              "      <td>-106.000000</td>\n",
              "      <td>-136.000000</td>\n",
              "      <td>-200.000000</td>\n",
              "      <td>-213.000000</td>\n",
              "      <td>-190.000000</td>\n",
              "      <td>-140.000000</td>\n",
              "      <td>-128.000000</td>\n",
              "      <td>-114.000000</td>\n",
              "      <td>-173.000000</td>\n",
              "      <td>-143.000000</td>\n",
              "      <td>-198.000000</td>\n",
              "      <td>-257.000000</td>\n",
              "      <td>-328.000000</td>\n",
              "      <td>-219.000000</td>\n",
              "      <td>-136.000000</td>\n",
              "      <td>-120.000000</td>\n",
              "      <td>-69.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>-289.000000</td>\n",
              "      <td>-428.000000</td>\n",
              "      <td>-471.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1650.25000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>-193.000000</td>\n",
              "      <td>-137.000000</td>\n",
              "      <td>-70.000000</td>\n",
              "      <td>-117.000000</td>\n",
              "      <td>-28.000000</td>\n",
              "      <td>-159.000000</td>\n",
              "      <td>-85.000000</td>\n",
              "      <td>-217.000000</td>\n",
              "      <td>-96.750000</td>\n",
              "      <td>-207.000000</td>\n",
              "      <td>-114.000000</td>\n",
              "      <td>-85.000000</td>\n",
              "      <td>-199.750000</td>\n",
              "      <td>-195.000000</td>\n",
              "      <td>-301.000000</td>\n",
              "      <td>-177.000000</td>\n",
              "      <td>-85.000000</td>\n",
              "      <td>-98.000000</td>\n",
              "      <td>-60.000000</td>\n",
              "      <td>-118.000000</td>\n",
              "      <td>-180.000000</td>\n",
              "      <td>-154.000000</td>\n",
              "      <td>-61.000000</td>\n",
              "      <td>-95.000000</td>\n",
              "      <td>-182.000000</td>\n",
              "      <td>-105.000000</td>\n",
              "      <td>-154.000000</td>\n",
              "      <td>-44.000000</td>\n",
              "      <td>-135.000000</td>\n",
              "      <td>-116.000000</td>\n",
              "      <td>-91.000000</td>\n",
              "      <td>-81.000000</td>\n",
              "      <td>-211.000000</td>\n",
              "      <td>-136.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>-174.000000</td>\n",
              "      <td>-82.000000</td>\n",
              "      <td>-144.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-170.000000</td>\n",
              "      <td>-112.000000</td>\n",
              "      <td>-187.000000</td>\n",
              "      <td>-43.000000</td>\n",
              "      <td>-115.000000</td>\n",
              "      <td>-94.000000</td>\n",
              "      <td>-126.000000</td>\n",
              "      <td>-172.000000</td>\n",
              "      <td>-84.000000</td>\n",
              "      <td>-111.750000</td>\n",
              "      <td>-88.000000</td>\n",
              "      <td>-164.000000</td>\n",
              "      <td>-71.000000</td>\n",
              "      <td>-101.000000</td>\n",
              "      <td>-83.750000</td>\n",
              "      <td>-133.000000</td>\n",
              "      <td>-156.000000</td>\n",
              "      <td>-178.000000</td>\n",
              "      <td>-103.000000</td>\n",
              "      <td>-121.000000</td>\n",
              "      <td>-59.000000</td>\n",
              "      <td>-90.000000</td>\n",
              "      <td>-45.000000</td>\n",
              "      <td>-101.000000</td>\n",
              "      <td>-123.000000</td>\n",
              "      <td>-112.000000</td>\n",
              "      <td>-166.000000</td>\n",
              "      <td>-43.000000</td>\n",
              "      <td>-183.000000</td>\n",
              "      <td>-240.000000</td>\n",
              "      <td>-272.000000</td>\n",
              "      <td>-205.000000</td>\n",
              "      <td>-70.000000</td>\n",
              "      <td>-18.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>-68.000000</td>\n",
              "      <td>-179.000000</td>\n",
              "      <td>-9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3299.50000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>-149.000000</td>\n",
              "      <td>-99.000000</td>\n",
              "      <td>-25.000000</td>\n",
              "      <td>-117.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>-40.000000</td>\n",
              "      <td>-29.000000</td>\n",
              "      <td>-83.000000</td>\n",
              "      <td>-86.000000</td>\n",
              "      <td>-66.000000</td>\n",
              "      <td>-92.000000</td>\n",
              "      <td>-89.000000</td>\n",
              "      <td>-290.000000</td>\n",
              "      <td>-53.000000</td>\n",
              "      <td>-69.000000</td>\n",
              "      <td>-39.000000</td>\n",
              "      <td>-38.000000</td>\n",
              "      <td>-63.000000</td>\n",
              "      <td>-19.000000</td>\n",
              "      <td>-41.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>-35.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>-132.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>-116.000000</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>-24.000000</td>\n",
              "      <td>-32.000000</td>\n",
              "      <td>-120.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>-167.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>-104.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>-70.000000</td>\n",
              "      <td>-131.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>-57.500000</td>\n",
              "      <td>-78.000000</td>\n",
              "      <td>-87.000000</td>\n",
              "      <td>-80.500000</td>\n",
              "      <td>-26.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>-47.000000</td>\n",
              "      <td>-34.500000</td>\n",
              "      <td>-48.000000</td>\n",
              "      <td>-64.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>-178.000000</td>\n",
              "      <td>-103.000000</td>\n",
              "      <td>-119.000000</td>\n",
              "      <td>-31.000000</td>\n",
              "      <td>-52.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>-63.000000</td>\n",
              "      <td>-113.000000</td>\n",
              "      <td>-111.000000</td>\n",
              "      <td>-61.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>-31.000000</td>\n",
              "      <td>-236.000000</td>\n",
              "      <td>-234.000000</td>\n",
              "      <td>-131.000000</td>\n",
              "      <td>-21.000000</td>\n",
              "      <td>61.500000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>191.000000</td>\n",
              "      <td>-60.000000</td>\n",
              "      <td>-150.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4948.75000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>-95.000000</td>\n",
              "      <td>-19.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>-116.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>-21.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>-46.000000</td>\n",
              "      <td>-35.000000</td>\n",
              "      <td>-45.000000</td>\n",
              "      <td>-72.000000</td>\n",
              "      <td>-73.000000</td>\n",
              "      <td>-273.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>-46.000000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>-11.000000</td>\n",
              "      <td>-37.000000</td>\n",
              "      <td>-9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>-85.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>-108.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>-11.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>-22.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>-140.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>-25.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>-30.000000</td>\n",
              "      <td>-25.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>-64.000000</td>\n",
              "      <td>-61.000000</td>\n",
              "      <td>-37.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>-16.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-33.000000</td>\n",
              "      <td>-36.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>-178.000000</td>\n",
              "      <td>-101.000000</td>\n",
              "      <td>-115.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>-17.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>-25.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>-41.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>-231.000000</td>\n",
              "      <td>-80.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>215.000000</td>\n",
              "      <td>-45.000000</td>\n",
              "      <td>-120.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6598.00000</td>\n",
              "      <td>292.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>161.000000</td>\n",
              "      <td>325.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>176.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>189.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>227.000000</td>\n",
              "      <td>194.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>213.000000</td>\n",
              "      <td>317.000000</td>\n",
              "      <td>277.000000</td>\n",
              "      <td>183.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>309.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>324.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>241.000000</td>\n",
              "      <td>206.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>281.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>176.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>219.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>203.000000</td>\n",
              "      <td>188.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>239.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>213.000000</td>\n",
              "      <td>261.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>244.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>211.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>379.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>179.000000</td>\n",
              "      <td>192.000000</td>\n",
              "      <td>411.000000</td>\n",
              "      <td>355.000000</td>\n",
              "      <td>625.000000</td>\n",
              "      <td>295.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>367.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 168 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID           f1  ...         f166        class\n",
              "count  6598.00000  6598.000000  ...  6598.000000  6598.000000\n",
              "mean   3299.50000    58.945135  ...    41.770233     0.154138\n",
              "std    1904.82287    53.249007  ...    94.116085     0.361108\n",
              "min       1.00000   -31.000000  ...  -471.000000     0.000000\n",
              "25%    1650.25000    37.000000  ...    -9.000000     0.000000\n",
              "50%    3299.50000    44.000000  ...    27.000000     0.000000\n",
              "75%    4948.75000    53.000000  ...   119.000000     0.000000\n",
              "max    6598.00000   292.000000  ...   367.000000     1.000000\n",
              "\n",
              "[8 rows x 168 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAGHzFLrH9xJ",
        "colab_type": "text"
      },
      "source": [
        "## Removing the Unnecessary Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itMPdMqCc5Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop([\"ID\",\"molecule_name\",\"conformation_name\"],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfEiLVMpc5Yl",
        "colab_type": "code",
        "outputId": "ecc16ba5-8e5d-4b51-ff7c-a739cb684b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6598, 167)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEB3Ih2Zc5Yw",
        "colab_type": "code",
        "outputId": "1107fa89-31b6-496c-c746-17239912def8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>f39</th>\n",
              "      <th>f40</th>\n",
              "      <th>...</th>\n",
              "      <th>f128</th>\n",
              "      <th>f129</th>\n",
              "      <th>f130</th>\n",
              "      <th>f131</th>\n",
              "      <th>f132</th>\n",
              "      <th>f133</th>\n",
              "      <th>f134</th>\n",
              "      <th>f135</th>\n",
              "      <th>f136</th>\n",
              "      <th>f137</th>\n",
              "      <th>f138</th>\n",
              "      <th>f139</th>\n",
              "      <th>f140</th>\n",
              "      <th>f141</th>\n",
              "      <th>f142</th>\n",
              "      <th>f143</th>\n",
              "      <th>f144</th>\n",
              "      <th>f145</th>\n",
              "      <th>f146</th>\n",
              "      <th>f147</th>\n",
              "      <th>f148</th>\n",
              "      <th>f149</th>\n",
              "      <th>f150</th>\n",
              "      <th>f151</th>\n",
              "      <th>f152</th>\n",
              "      <th>f153</th>\n",
              "      <th>f154</th>\n",
              "      <th>f155</th>\n",
              "      <th>f156</th>\n",
              "      <th>f157</th>\n",
              "      <th>f158</th>\n",
              "      <th>f159</th>\n",
              "      <th>f160</th>\n",
              "      <th>f161</th>\n",
              "      <th>f162</th>\n",
              "      <th>f163</th>\n",
              "      <th>f164</th>\n",
              "      <th>f165</th>\n",
              "      <th>f166</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46</td>\n",
              "      <td>-108</td>\n",
              "      <td>-60</td>\n",
              "      <td>-69</td>\n",
              "      <td>-117</td>\n",
              "      <td>49</td>\n",
              "      <td>38</td>\n",
              "      <td>-161</td>\n",
              "      <td>-8</td>\n",
              "      <td>5</td>\n",
              "      <td>-323</td>\n",
              "      <td>-220</td>\n",
              "      <td>-113</td>\n",
              "      <td>-299</td>\n",
              "      <td>-283</td>\n",
              "      <td>-307</td>\n",
              "      <td>-31</td>\n",
              "      <td>-106</td>\n",
              "      <td>-227</td>\n",
              "      <td>-42</td>\n",
              "      <td>-59</td>\n",
              "      <td>-22</td>\n",
              "      <td>-67</td>\n",
              "      <td>189</td>\n",
              "      <td>81</td>\n",
              "      <td>17</td>\n",
              "      <td>-27</td>\n",
              "      <td>-89</td>\n",
              "      <td>-67</td>\n",
              "      <td>105</td>\n",
              "      <td>-116</td>\n",
              "      <td>124</td>\n",
              "      <td>-106</td>\n",
              "      <td>5</td>\n",
              "      <td>-120</td>\n",
              "      <td>63</td>\n",
              "      <td>-165</td>\n",
              "      <td>40</td>\n",
              "      <td>-27</td>\n",
              "      <td>68</td>\n",
              "      <td>...</td>\n",
              "      <td>81</td>\n",
              "      <td>-114</td>\n",
              "      <td>-187</td>\n",
              "      <td>45</td>\n",
              "      <td>-118</td>\n",
              "      <td>-75</td>\n",
              "      <td>-182</td>\n",
              "      <td>-234</td>\n",
              "      <td>-19</td>\n",
              "      <td>12</td>\n",
              "      <td>-13</td>\n",
              "      <td>-41</td>\n",
              "      <td>-119</td>\n",
              "      <td>-149</td>\n",
              "      <td>70</td>\n",
              "      <td>17</td>\n",
              "      <td>-20</td>\n",
              "      <td>-177</td>\n",
              "      <td>-101</td>\n",
              "      <td>-116</td>\n",
              "      <td>-14</td>\n",
              "      <td>-50</td>\n",
              "      <td>24</td>\n",
              "      <td>-81</td>\n",
              "      <td>-125</td>\n",
              "      <td>-114</td>\n",
              "      <td>-44</td>\n",
              "      <td>128</td>\n",
              "      <td>3</td>\n",
              "      <td>-244</td>\n",
              "      <td>-308</td>\n",
              "      <td>52</td>\n",
              "      <td>-7</td>\n",
              "      <td>39</td>\n",
              "      <td>126</td>\n",
              "      <td>156</td>\n",
              "      <td>-50</td>\n",
              "      <td>-112</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41</td>\n",
              "      <td>-188</td>\n",
              "      <td>-145</td>\n",
              "      <td>22</td>\n",
              "      <td>-117</td>\n",
              "      <td>-6</td>\n",
              "      <td>57</td>\n",
              "      <td>-171</td>\n",
              "      <td>-39</td>\n",
              "      <td>-100</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-228</td>\n",
              "      <td>-281</td>\n",
              "      <td>-281</td>\n",
              "      <td>-300</td>\n",
              "      <td>54</td>\n",
              "      <td>-149</td>\n",
              "      <td>-98</td>\n",
              "      <td>-196</td>\n",
              "      <td>-27</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>75</td>\n",
              "      <td>49</td>\n",
              "      <td>-34</td>\n",
              "      <td>45</td>\n",
              "      <td>-91</td>\n",
              "      <td>32</td>\n",
              "      <td>95</td>\n",
              "      <td>-116</td>\n",
              "      <td>85</td>\n",
              "      <td>-23</td>\n",
              "      <td>42</td>\n",
              "      <td>-58</td>\n",
              "      <td>61</td>\n",
              "      <td>-171</td>\n",
              "      <td>2</td>\n",
              "      <td>-144</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>-21</td>\n",
              "      <td>-32</td>\n",
              "      <td>32</td>\n",
              "      <td>-128</td>\n",
              "      <td>-72</td>\n",
              "      <td>-124</td>\n",
              "      <td>-218</td>\n",
              "      <td>-94</td>\n",
              "      <td>53</td>\n",
              "      <td>-79</td>\n",
              "      <td>-20</td>\n",
              "      <td>-35</td>\n",
              "      <td>-26</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-102</td>\n",
              "      <td>-121</td>\n",
              "      <td>-66</td>\n",
              "      <td>-77</td>\n",
              "      <td>51</td>\n",
              "      <td>-41</td>\n",
              "      <td>-34</td>\n",
              "      <td>-32</td>\n",
              "      <td>-63</td>\n",
              "      <td>115</td>\n",
              "      <td>-5</td>\n",
              "      <td>-235</td>\n",
              "      <td>-59</td>\n",
              "      <td>-2</td>\n",
              "      <td>52</td>\n",
              "      <td>103</td>\n",
              "      <td>136</td>\n",
              "      <td>169</td>\n",
              "      <td>-61</td>\n",
              "      <td>-136</td>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46</td>\n",
              "      <td>-194</td>\n",
              "      <td>-145</td>\n",
              "      <td>28</td>\n",
              "      <td>-117</td>\n",
              "      <td>73</td>\n",
              "      <td>57</td>\n",
              "      <td>-168</td>\n",
              "      <td>-39</td>\n",
              "      <td>-22</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-104</td>\n",
              "      <td>-283</td>\n",
              "      <td>-282</td>\n",
              "      <td>-303</td>\n",
              "      <td>52</td>\n",
              "      <td>-152</td>\n",
              "      <td>-97</td>\n",
              "      <td>-225</td>\n",
              "      <td>-28</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>179</td>\n",
              "      <td>49</td>\n",
              "      <td>-33</td>\n",
              "      <td>46</td>\n",
              "      <td>-88</td>\n",
              "      <td>22</td>\n",
              "      <td>79</td>\n",
              "      <td>-116</td>\n",
              "      <td>19</td>\n",
              "      <td>-11</td>\n",
              "      <td>6</td>\n",
              "      <td>-38</td>\n",
              "      <td>71</td>\n",
              "      <td>-175</td>\n",
              "      <td>3</td>\n",
              "      <td>-129</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>-23</td>\n",
              "      <td>-15</td>\n",
              "      <td>-129</td>\n",
              "      <td>-74</td>\n",
              "      <td>-125</td>\n",
              "      <td>-221</td>\n",
              "      <td>-93</td>\n",
              "      <td>53</td>\n",
              "      <td>-72</td>\n",
              "      <td>-19</td>\n",
              "      <td>-33</td>\n",
              "      <td>-26</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-102</td>\n",
              "      <td>-119</td>\n",
              "      <td>-66</td>\n",
              "      <td>-81</td>\n",
              "      <td>51</td>\n",
              "      <td>-41</td>\n",
              "      <td>-27</td>\n",
              "      <td>-41</td>\n",
              "      <td>-140</td>\n",
              "      <td>77</td>\n",
              "      <td>-163</td>\n",
              "      <td>-238</td>\n",
              "      <td>-134</td>\n",
              "      <td>-154</td>\n",
              "      <td>57</td>\n",
              "      <td>143</td>\n",
              "      <td>142</td>\n",
              "      <td>165</td>\n",
              "      <td>-67</td>\n",
              "      <td>-145</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41</td>\n",
              "      <td>-188</td>\n",
              "      <td>-145</td>\n",
              "      <td>22</td>\n",
              "      <td>-117</td>\n",
              "      <td>-7</td>\n",
              "      <td>57</td>\n",
              "      <td>-170</td>\n",
              "      <td>-39</td>\n",
              "      <td>-99</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-228</td>\n",
              "      <td>-282</td>\n",
              "      <td>-281</td>\n",
              "      <td>-301</td>\n",
              "      <td>54</td>\n",
              "      <td>-150</td>\n",
              "      <td>-98</td>\n",
              "      <td>-196</td>\n",
              "      <td>-28</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>77</td>\n",
              "      <td>48</td>\n",
              "      <td>-34</td>\n",
              "      <td>46</td>\n",
              "      <td>-91</td>\n",
              "      <td>32</td>\n",
              "      <td>94</td>\n",
              "      <td>-116</td>\n",
              "      <td>84</td>\n",
              "      <td>-23</td>\n",
              "      <td>41</td>\n",
              "      <td>-58</td>\n",
              "      <td>62</td>\n",
              "      <td>-171</td>\n",
              "      <td>3</td>\n",
              "      <td>-144</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>-20</td>\n",
              "      <td>-32</td>\n",
              "      <td>32</td>\n",
              "      <td>-128</td>\n",
              "      <td>-73</td>\n",
              "      <td>-125</td>\n",
              "      <td>-220</td>\n",
              "      <td>-93</td>\n",
              "      <td>53</td>\n",
              "      <td>-78</td>\n",
              "      <td>-19</td>\n",
              "      <td>-34</td>\n",
              "      <td>-26</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-101</td>\n",
              "      <td>-121</td>\n",
              "      <td>-65</td>\n",
              "      <td>-77</td>\n",
              "      <td>52</td>\n",
              "      <td>-41</td>\n",
              "      <td>-34</td>\n",
              "      <td>-32</td>\n",
              "      <td>-66</td>\n",
              "      <td>115</td>\n",
              "      <td>-7</td>\n",
              "      <td>-236</td>\n",
              "      <td>-60</td>\n",
              "      <td>-4</td>\n",
              "      <td>52</td>\n",
              "      <td>104</td>\n",
              "      <td>136</td>\n",
              "      <td>168</td>\n",
              "      <td>-60</td>\n",
              "      <td>-135</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>-188</td>\n",
              "      <td>-145</td>\n",
              "      <td>22</td>\n",
              "      <td>-117</td>\n",
              "      <td>-7</td>\n",
              "      <td>57</td>\n",
              "      <td>-170</td>\n",
              "      <td>-39</td>\n",
              "      <td>-99</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-228</td>\n",
              "      <td>-282</td>\n",
              "      <td>-281</td>\n",
              "      <td>-301</td>\n",
              "      <td>54</td>\n",
              "      <td>-150</td>\n",
              "      <td>-98</td>\n",
              "      <td>-196</td>\n",
              "      <td>-28</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>78</td>\n",
              "      <td>48</td>\n",
              "      <td>-34</td>\n",
              "      <td>46</td>\n",
              "      <td>-91</td>\n",
              "      <td>31</td>\n",
              "      <td>94</td>\n",
              "      <td>-116</td>\n",
              "      <td>84</td>\n",
              "      <td>-23</td>\n",
              "      <td>41</td>\n",
              "      <td>-58</td>\n",
              "      <td>62</td>\n",
              "      <td>-171</td>\n",
              "      <td>3</td>\n",
              "      <td>-144</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>-20</td>\n",
              "      <td>-32</td>\n",
              "      <td>32</td>\n",
              "      <td>-128</td>\n",
              "      <td>-73</td>\n",
              "      <td>-125</td>\n",
              "      <td>-220</td>\n",
              "      <td>-93</td>\n",
              "      <td>53</td>\n",
              "      <td>-78</td>\n",
              "      <td>-19</td>\n",
              "      <td>-34</td>\n",
              "      <td>-26</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-101</td>\n",
              "      <td>-121</td>\n",
              "      <td>-65</td>\n",
              "      <td>-76</td>\n",
              "      <td>52</td>\n",
              "      <td>-41</td>\n",
              "      <td>-34</td>\n",
              "      <td>-32</td>\n",
              "      <td>-66</td>\n",
              "      <td>115</td>\n",
              "      <td>-8</td>\n",
              "      <td>-236</td>\n",
              "      <td>-60</td>\n",
              "      <td>-4</td>\n",
              "      <td>52</td>\n",
              "      <td>104</td>\n",
              "      <td>137</td>\n",
              "      <td>168</td>\n",
              "      <td>-60</td>\n",
              "      <td>-135</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 167 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   f1   f2   f3  f4   f5  f6  f7  ...  f161  f162  f163  f164  f165  f166  class\n",
              "0  46 -108  -60 -69 -117  49  38  ...    39   126   156   -50  -112    96      1\n",
              "1  41 -188 -145  22 -117  -6  57  ...   103   136   169   -61  -136    79      1\n",
              "2  46 -194 -145  28 -117  73  57  ...   143   142   165   -67  -145    39      1\n",
              "3  41 -188 -145  22 -117  -7  57  ...   104   136   168   -60  -135    80      1\n",
              "4  41 -188 -145  22 -117  -7  57  ...   104   137   168   -60  -135    80      1\n",
              "\n",
              "[5 rows x 167 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9w1wDU7IFuG",
        "colab_type": "text"
      },
      "source": [
        "## Spliting Data and Target (x and y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p17GELHeLVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=data.drop(\"class\",axis=1)\n",
        "y=data[\"class\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12MqHi78ek6x",
        "colab_type": "code",
        "outputId": "b16d795d-48d3-4365-b0b5-909f9caf7b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape,y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6598, 166), (6598,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIf-BuFQezne",
        "colab_type": "code",
        "outputId": "9acfe954-e587-4f91-abaf-39edf753fe41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "x.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>f39</th>\n",
              "      <th>f40</th>\n",
              "      <th>...</th>\n",
              "      <th>f127</th>\n",
              "      <th>f128</th>\n",
              "      <th>f129</th>\n",
              "      <th>f130</th>\n",
              "      <th>f131</th>\n",
              "      <th>f132</th>\n",
              "      <th>f133</th>\n",
              "      <th>f134</th>\n",
              "      <th>f135</th>\n",
              "      <th>f136</th>\n",
              "      <th>f137</th>\n",
              "      <th>f138</th>\n",
              "      <th>f139</th>\n",
              "      <th>f140</th>\n",
              "      <th>f141</th>\n",
              "      <th>f142</th>\n",
              "      <th>f143</th>\n",
              "      <th>f144</th>\n",
              "      <th>f145</th>\n",
              "      <th>f146</th>\n",
              "      <th>f147</th>\n",
              "      <th>f148</th>\n",
              "      <th>f149</th>\n",
              "      <th>f150</th>\n",
              "      <th>f151</th>\n",
              "      <th>f152</th>\n",
              "      <th>f153</th>\n",
              "      <th>f154</th>\n",
              "      <th>f155</th>\n",
              "      <th>f156</th>\n",
              "      <th>f157</th>\n",
              "      <th>f158</th>\n",
              "      <th>f159</th>\n",
              "      <th>f160</th>\n",
              "      <th>f161</th>\n",
              "      <th>f162</th>\n",
              "      <th>f163</th>\n",
              "      <th>f164</th>\n",
              "      <th>f165</th>\n",
              "      <th>f166</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46</td>\n",
              "      <td>-108</td>\n",
              "      <td>-60</td>\n",
              "      <td>-69</td>\n",
              "      <td>-117</td>\n",
              "      <td>49</td>\n",
              "      <td>38</td>\n",
              "      <td>-161</td>\n",
              "      <td>-8</td>\n",
              "      <td>5</td>\n",
              "      <td>-323</td>\n",
              "      <td>-220</td>\n",
              "      <td>-113</td>\n",
              "      <td>-299</td>\n",
              "      <td>-283</td>\n",
              "      <td>-307</td>\n",
              "      <td>-31</td>\n",
              "      <td>-106</td>\n",
              "      <td>-227</td>\n",
              "      <td>-42</td>\n",
              "      <td>-59</td>\n",
              "      <td>-22</td>\n",
              "      <td>-67</td>\n",
              "      <td>189</td>\n",
              "      <td>81</td>\n",
              "      <td>17</td>\n",
              "      <td>-27</td>\n",
              "      <td>-89</td>\n",
              "      <td>-67</td>\n",
              "      <td>105</td>\n",
              "      <td>-116</td>\n",
              "      <td>124</td>\n",
              "      <td>-106</td>\n",
              "      <td>5</td>\n",
              "      <td>-120</td>\n",
              "      <td>63</td>\n",
              "      <td>-165</td>\n",
              "      <td>40</td>\n",
              "      <td>-27</td>\n",
              "      <td>68</td>\n",
              "      <td>...</td>\n",
              "      <td>-27</td>\n",
              "      <td>81</td>\n",
              "      <td>-114</td>\n",
              "      <td>-187</td>\n",
              "      <td>45</td>\n",
              "      <td>-118</td>\n",
              "      <td>-75</td>\n",
              "      <td>-182</td>\n",
              "      <td>-234</td>\n",
              "      <td>-19</td>\n",
              "      <td>12</td>\n",
              "      <td>-13</td>\n",
              "      <td>-41</td>\n",
              "      <td>-119</td>\n",
              "      <td>-149</td>\n",
              "      <td>70</td>\n",
              "      <td>17</td>\n",
              "      <td>-20</td>\n",
              "      <td>-177</td>\n",
              "      <td>-101</td>\n",
              "      <td>-116</td>\n",
              "      <td>-14</td>\n",
              "      <td>-50</td>\n",
              "      <td>24</td>\n",
              "      <td>-81</td>\n",
              "      <td>-125</td>\n",
              "      <td>-114</td>\n",
              "      <td>-44</td>\n",
              "      <td>128</td>\n",
              "      <td>3</td>\n",
              "      <td>-244</td>\n",
              "      <td>-308</td>\n",
              "      <td>52</td>\n",
              "      <td>-7</td>\n",
              "      <td>39</td>\n",
              "      <td>126</td>\n",
              "      <td>156</td>\n",
              "      <td>-50</td>\n",
              "      <td>-112</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41</td>\n",
              "      <td>-188</td>\n",
              "      <td>-145</td>\n",
              "      <td>22</td>\n",
              "      <td>-117</td>\n",
              "      <td>-6</td>\n",
              "      <td>57</td>\n",
              "      <td>-171</td>\n",
              "      <td>-39</td>\n",
              "      <td>-100</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-228</td>\n",
              "      <td>-281</td>\n",
              "      <td>-281</td>\n",
              "      <td>-300</td>\n",
              "      <td>54</td>\n",
              "      <td>-149</td>\n",
              "      <td>-98</td>\n",
              "      <td>-196</td>\n",
              "      <td>-27</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>75</td>\n",
              "      <td>49</td>\n",
              "      <td>-34</td>\n",
              "      <td>45</td>\n",
              "      <td>-91</td>\n",
              "      <td>32</td>\n",
              "      <td>95</td>\n",
              "      <td>-116</td>\n",
              "      <td>85</td>\n",
              "      <td>-23</td>\n",
              "      <td>42</td>\n",
              "      <td>-58</td>\n",
              "      <td>61</td>\n",
              "      <td>-171</td>\n",
              "      <td>2</td>\n",
              "      <td>-144</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>17</td>\n",
              "      <td>88</td>\n",
              "      <td>-21</td>\n",
              "      <td>-32</td>\n",
              "      <td>32</td>\n",
              "      <td>-128</td>\n",
              "      <td>-72</td>\n",
              "      <td>-124</td>\n",
              "      <td>-218</td>\n",
              "      <td>-94</td>\n",
              "      <td>53</td>\n",
              "      <td>-79</td>\n",
              "      <td>-20</td>\n",
              "      <td>-35</td>\n",
              "      <td>-26</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-102</td>\n",
              "      <td>-121</td>\n",
              "      <td>-66</td>\n",
              "      <td>-77</td>\n",
              "      <td>51</td>\n",
              "      <td>-41</td>\n",
              "      <td>-34</td>\n",
              "      <td>-32</td>\n",
              "      <td>-63</td>\n",
              "      <td>115</td>\n",
              "      <td>-5</td>\n",
              "      <td>-235</td>\n",
              "      <td>-59</td>\n",
              "      <td>-2</td>\n",
              "      <td>52</td>\n",
              "      <td>103</td>\n",
              "      <td>136</td>\n",
              "      <td>169</td>\n",
              "      <td>-61</td>\n",
              "      <td>-136</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46</td>\n",
              "      <td>-194</td>\n",
              "      <td>-145</td>\n",
              "      <td>28</td>\n",
              "      <td>-117</td>\n",
              "      <td>73</td>\n",
              "      <td>57</td>\n",
              "      <td>-168</td>\n",
              "      <td>-39</td>\n",
              "      <td>-22</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-104</td>\n",
              "      <td>-283</td>\n",
              "      <td>-282</td>\n",
              "      <td>-303</td>\n",
              "      <td>52</td>\n",
              "      <td>-152</td>\n",
              "      <td>-97</td>\n",
              "      <td>-225</td>\n",
              "      <td>-28</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>179</td>\n",
              "      <td>49</td>\n",
              "      <td>-33</td>\n",
              "      <td>46</td>\n",
              "      <td>-88</td>\n",
              "      <td>22</td>\n",
              "      <td>79</td>\n",
              "      <td>-116</td>\n",
              "      <td>19</td>\n",
              "      <td>-11</td>\n",
              "      <td>6</td>\n",
              "      <td>-38</td>\n",
              "      <td>71</td>\n",
              "      <td>-175</td>\n",
              "      <td>3</td>\n",
              "      <td>-129</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>41</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>-23</td>\n",
              "      <td>-15</td>\n",
              "      <td>-129</td>\n",
              "      <td>-74</td>\n",
              "      <td>-125</td>\n",
              "      <td>-221</td>\n",
              "      <td>-93</td>\n",
              "      <td>53</td>\n",
              "      <td>-72</td>\n",
              "      <td>-19</td>\n",
              "      <td>-33</td>\n",
              "      <td>-26</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-102</td>\n",
              "      <td>-119</td>\n",
              "      <td>-66</td>\n",
              "      <td>-81</td>\n",
              "      <td>51</td>\n",
              "      <td>-41</td>\n",
              "      <td>-27</td>\n",
              "      <td>-41</td>\n",
              "      <td>-140</td>\n",
              "      <td>77</td>\n",
              "      <td>-163</td>\n",
              "      <td>-238</td>\n",
              "      <td>-134</td>\n",
              "      <td>-154</td>\n",
              "      <td>57</td>\n",
              "      <td>143</td>\n",
              "      <td>142</td>\n",
              "      <td>165</td>\n",
              "      <td>-67</td>\n",
              "      <td>-145</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41</td>\n",
              "      <td>-188</td>\n",
              "      <td>-145</td>\n",
              "      <td>22</td>\n",
              "      <td>-117</td>\n",
              "      <td>-7</td>\n",
              "      <td>57</td>\n",
              "      <td>-170</td>\n",
              "      <td>-39</td>\n",
              "      <td>-99</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-228</td>\n",
              "      <td>-282</td>\n",
              "      <td>-281</td>\n",
              "      <td>-301</td>\n",
              "      <td>54</td>\n",
              "      <td>-150</td>\n",
              "      <td>-98</td>\n",
              "      <td>-196</td>\n",
              "      <td>-28</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>77</td>\n",
              "      <td>48</td>\n",
              "      <td>-34</td>\n",
              "      <td>46</td>\n",
              "      <td>-91</td>\n",
              "      <td>32</td>\n",
              "      <td>94</td>\n",
              "      <td>-116</td>\n",
              "      <td>84</td>\n",
              "      <td>-23</td>\n",
              "      <td>41</td>\n",
              "      <td>-58</td>\n",
              "      <td>62</td>\n",
              "      <td>-171</td>\n",
              "      <td>3</td>\n",
              "      <td>-144</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>17</td>\n",
              "      <td>88</td>\n",
              "      <td>-20</td>\n",
              "      <td>-32</td>\n",
              "      <td>32</td>\n",
              "      <td>-128</td>\n",
              "      <td>-73</td>\n",
              "      <td>-125</td>\n",
              "      <td>-220</td>\n",
              "      <td>-93</td>\n",
              "      <td>53</td>\n",
              "      <td>-78</td>\n",
              "      <td>-19</td>\n",
              "      <td>-34</td>\n",
              "      <td>-26</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-101</td>\n",
              "      <td>-121</td>\n",
              "      <td>-65</td>\n",
              "      <td>-77</td>\n",
              "      <td>52</td>\n",
              "      <td>-41</td>\n",
              "      <td>-34</td>\n",
              "      <td>-32</td>\n",
              "      <td>-66</td>\n",
              "      <td>115</td>\n",
              "      <td>-7</td>\n",
              "      <td>-236</td>\n",
              "      <td>-60</td>\n",
              "      <td>-4</td>\n",
              "      <td>52</td>\n",
              "      <td>104</td>\n",
              "      <td>136</td>\n",
              "      <td>168</td>\n",
              "      <td>-60</td>\n",
              "      <td>-135</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>-188</td>\n",
              "      <td>-145</td>\n",
              "      <td>22</td>\n",
              "      <td>-117</td>\n",
              "      <td>-7</td>\n",
              "      <td>57</td>\n",
              "      <td>-170</td>\n",
              "      <td>-39</td>\n",
              "      <td>-99</td>\n",
              "      <td>-319</td>\n",
              "      <td>-111</td>\n",
              "      <td>-228</td>\n",
              "      <td>-282</td>\n",
              "      <td>-281</td>\n",
              "      <td>-301</td>\n",
              "      <td>54</td>\n",
              "      <td>-150</td>\n",
              "      <td>-98</td>\n",
              "      <td>-196</td>\n",
              "      <td>-28</td>\n",
              "      <td>-22</td>\n",
              "      <td>2</td>\n",
              "      <td>78</td>\n",
              "      <td>48</td>\n",
              "      <td>-34</td>\n",
              "      <td>46</td>\n",
              "      <td>-91</td>\n",
              "      <td>31</td>\n",
              "      <td>94</td>\n",
              "      <td>-116</td>\n",
              "      <td>84</td>\n",
              "      <td>-23</td>\n",
              "      <td>41</td>\n",
              "      <td>-58</td>\n",
              "      <td>62</td>\n",
              "      <td>-171</td>\n",
              "      <td>3</td>\n",
              "      <td>-144</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>17</td>\n",
              "      <td>88</td>\n",
              "      <td>-20</td>\n",
              "      <td>-32</td>\n",
              "      <td>32</td>\n",
              "      <td>-128</td>\n",
              "      <td>-73</td>\n",
              "      <td>-125</td>\n",
              "      <td>-220</td>\n",
              "      <td>-93</td>\n",
              "      <td>53</td>\n",
              "      <td>-78</td>\n",
              "      <td>-19</td>\n",
              "      <td>-34</td>\n",
              "      <td>-26</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>-177</td>\n",
              "      <td>-101</td>\n",
              "      <td>-121</td>\n",
              "      <td>-65</td>\n",
              "      <td>-76</td>\n",
              "      <td>52</td>\n",
              "      <td>-41</td>\n",
              "      <td>-34</td>\n",
              "      <td>-32</td>\n",
              "      <td>-66</td>\n",
              "      <td>115</td>\n",
              "      <td>-8</td>\n",
              "      <td>-236</td>\n",
              "      <td>-60</td>\n",
              "      <td>-4</td>\n",
              "      <td>52</td>\n",
              "      <td>104</td>\n",
              "      <td>137</td>\n",
              "      <td>168</td>\n",
              "      <td>-60</td>\n",
              "      <td>-135</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 166 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   f1   f2   f3  f4   f5  f6  f7  ...  f160  f161  f162  f163  f164  f165  f166\n",
              "0  46 -108  -60 -69 -117  49  38  ...    -7    39   126   156   -50  -112    96\n",
              "1  41 -188 -145  22 -117  -6  57  ...    52   103   136   169   -61  -136    79\n",
              "2  46 -194 -145  28 -117  73  57  ...    57   143   142   165   -67  -145    39\n",
              "3  41 -188 -145  22 -117  -7  57  ...    52   104   136   168   -60  -135    80\n",
              "4  41 -188 -145  22 -117  -7  57  ...    52   104   137   168   -60  -135    80\n",
              "\n",
              "[5 rows x 166 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i665jpTIoom",
        "colab_type": "text"
      },
      "source": [
        "## Spliting Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBYKSwNgerav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=4,stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xZcO3i-faP3",
        "colab_type": "code",
        "outputId": "ef4712cf-9962-4f2f-b077-be69ec68cfa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape,y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5278, 166), (5278,), (1320, 166), (1320,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjuNmnFTI9F5",
        "colab_type": "text"
      },
      "source": [
        "### The Dataset contains features from f1 to f166\n",
        "> Features from f1 to f162 are the distance Meansure (Non-seq)\n",
        "\n",
        "> Features f163, f164, f165, f166 are the 3-Space Co-ordinaate (seq)\n",
        "\n",
        "### So splliting the Normal and 3-D Data, so i can handle both seperately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbA2KiW0faAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_non_seq_train = x_train.iloc[:,:162]\n",
        "x_seq_train = x_train.iloc[:,162:]\n",
        "\n",
        "x_non_seq_test = x_test.iloc[:,:162]\n",
        "x_seq_test = x_test.iloc[:,162:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cvZSb8OKWy2",
        "colab_type": "text"
      },
      "source": [
        "## Scaling the Distance Features (Non-seq)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG6Gu6U9c5Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "sc = StandardScaler() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB7l5miXc5Z8",
        "colab_type": "code",
        "outputId": "41faa81b-54e4-4825-8ae2-e5d55e4def38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(x_seq_train.shape)\n",
        "print(x_non_seq_train.shape)\n",
        "print(x_seq_test.shape)\n",
        "print(x_non_seq_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5278, 4)\n",
            "(5278, 162)\n",
            "(1320, 4)\n",
            "(1320, 162)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEqCdxfkheOw",
        "colab_type": "code",
        "outputId": "f4b1abbc-b4a1-40cb-d354-37621d807508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sc.fit(x_non_seq_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U490sM2Lhd5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_non_seq_train=sc.transform(x_non_seq_train)\n",
        "x_non_seq_test=sc.transform(x_non_seq_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsEYWuTkLDCC",
        "colab_type": "text"
      },
      "source": [
        "## As the dimension of Distance features are very large, so we can reduce that by using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN7RHkAZc5af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca=PCA()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh6iBVILc5al",
        "colab_type": "code",
        "outputId": "bc3cd56f-7ead-4fdd-ae40-18201504246d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "pca.fit(x_non_seq_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBFp2MUjc5au",
        "colab_type": "code",
        "outputId": "cca6d3f9-1443-4ad5-df7a-a3747e0c42c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "print(np.cumsum((pca.explained_variance_ratio_)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.29975468 0.48015878 0.52932522 0.57366232 0.6084202  0.64000075\n",
            " 0.66888761 0.69495775 0.71931478 0.7418363  0.76088437 0.77898498\n",
            " 0.79465514 0.80955565 0.82227768 0.83493188 0.84584421 0.85612397\n",
            " 0.86496165 0.87332978 0.88040513 0.88700223 0.89346006 0.89972182\n",
            " 0.90563468 0.91118605 0.91633883 0.92097806 0.92551984 0.92974209\n",
            " 0.93363391 0.9372676  0.9407305  0.94386689 0.94676542 0.94956324\n",
            " 0.95220359 0.95466063 0.95696614 0.95923299 0.96119551 0.96299176\n",
            " 0.96473823 0.96646331 0.96808181 0.96962936 0.9710942  0.97247019\n",
            " 0.97370315 0.97485123 0.97595223 0.97702616 0.97804829 0.97900524\n",
            " 0.97992524 0.98080548 0.98163986 0.98244731 0.98318311 0.98389992\n",
            " 0.98459467 0.9852764  0.9859329  0.98656563 0.98718367 0.98776941\n",
            " 0.98833566 0.98886501 0.98935626 0.98983234 0.99028372 0.99071416\n",
            " 0.99113558 0.99152544 0.99190337 0.9922664  0.99262385 0.99296927\n",
            " 0.99330042 0.99360552 0.99388582 0.99414843 0.99440897 0.99465257\n",
            " 0.99487557 0.99509325 0.99530388 0.99550077 0.99569336 0.99588158\n",
            " 0.99606022 0.99623066 0.99639695 0.99655173 0.99670081 0.99684706\n",
            " 0.99698751 0.99712198 0.99725306 0.99737665 0.99749675 0.9976106\n",
            " 0.99772007 0.99782721 0.99792942 0.99802584 0.99811981 0.99820988\n",
            " 0.99829762 0.99838193 0.99846299 0.99854187 0.9986203  0.99869325\n",
            " 0.9987641  0.99883026 0.99889347 0.99895409 0.99901345 0.99906657\n",
            " 0.99911852 0.99916957 0.99921574 0.99926165 0.99930489 0.9993472\n",
            " 0.99938844 0.99942768 0.99946435 0.99949927 0.99953311 0.99956527\n",
            " 0.99959703 0.99962774 0.99965763 0.99968528 0.99971166 0.99973578\n",
            " 0.9997588  0.99978058 0.99980157 0.99982067 0.99983933 0.99985701\n",
            " 0.99987379 0.9998888  0.99990317 0.9999156  0.99992659 0.99993592\n",
            " 0.99994489 0.99995289 0.99996059 0.99996759 0.99997395 0.99997969\n",
            " 0.99998466 0.99998864 0.99999252 0.99999575 0.99999845 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wE48SjALSIj",
        "colab_type": "text"
      },
      "source": [
        "## As it clear from above output, around 98% variance is explained by 56 component by PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-ULgiWHjMzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca=PCA(56)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r47jkd_ZLoD8",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the PCA on training and transforming on both train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k9YmopFjWV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca.fit(x_non_seq_train)\n",
        "x_non_seq_train=pca.transform(x_non_seq_train)\n",
        "x_non_seq_test=pca.transform(x_non_seq_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9XrXOaqL0nc",
        "colab_type": "text"
      },
      "source": [
        "### Confirming the shape after applying PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RN1lQGBc5a3",
        "colab_type": "code",
        "outputId": "f24ac8c7-0de9-4786-fa05-aafe3e18de2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_non_seq_train.shape,x_non_seq_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5278, 56), (1320, 56))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrK7tF3WL7PX",
        "colab_type": "text"
      },
      "source": [
        "## Function to create a Data for 3-D data (seq) so that it can be used in Sequence Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLwAADDVc5bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_signals(subset):\n",
        "    signal_data = []\n",
        "\n",
        "    for col in subset.columns:\n",
        "        res=subset[col].as_matrix()\n",
        "        res=res.reshape(-1,1)\n",
        "        signal_data.append(res)\n",
        "    return np.transpose(signal_data, (1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRQj2fmgNAzI",
        "colab_type": "text"
      },
      "source": [
        "### Shape before Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETB-maDZjxb9",
        "colab_type": "code",
        "outputId": "e76eea63-73f0-46f0-e4e3-9db38584f9c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_seq_train.shape,x_seq_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5278, 4), (1320, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gzfB_-dNGPH",
        "colab_type": "text"
      },
      "source": [
        "### Using Load_signals function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLzb7rPvc5bn",
        "colab_type": "code",
        "outputId": "b273e102-bddb-40b1-d46a-be541bfb9834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "x_seq_train=load_signals(x_seq_train)\n",
        "x_seq_test=load_signals(x_seq_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV85wxebNPax",
        "colab_type": "text"
      },
      "source": [
        "### After Transformation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss64drXwkZQo",
        "colab_type": "code",
        "outputId": "302c3283-2aee-4bf4-bbe6-3f4185bbcd67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_seq_train.shape,x_seq_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5278, 1, 4), (1320, 1, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEiJK9qNc5cG",
        "colab_type": "code",
        "outputId": "0a63ba31-1600-48ce-97b8-70fb8223cd09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_seq_train[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 177,  -42, -116,  126])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Izu_XBUO0X5",
        "colab_type": "text"
      },
      "source": [
        "## The Data is Imbalanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "StHzb9VFc5eL",
        "colab_type": "code",
        "outputId": "d9fbf4c1-dc0f-42d6-926c-9e3b743437ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "y.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5581\n",
              "1    1017\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1MAuPm5c5eO",
        "colab_type": "code",
        "outputId": "18bfa896-9b06-4f30-ef83-7edf833d123b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_ZgB3IO6OD",
        "colab_type": "text"
      },
      "source": [
        "## Calculating the weights of class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqyQsk-nc5eS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weight=class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL27h0SZc5eX",
        "colab_type": "code",
        "outputId": "96aa8dbb-99ae-4cdc-bc8e-5d6becde69c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.59117384, 3.24201474])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erXQJaFGpRPD",
        "colab_type": "code",
        "outputId": "9f951182-a3dc-49c9-9fe3-ce8825d4f1a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(x_non_seq_train.shape)\n",
        "print(x_non_seq_test.shape)\n",
        "print(x_seq_train.shape)\n",
        "print(x_seq_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5278, 56)\n",
            "(1320, 56)\n",
            "(5278, 1, 4)\n",
            "(1320, 1, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVCZFa4nNbb4",
        "colab_type": "text"
      },
      "source": [
        "# Model Architecture "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiKAPgiKNh1V",
        "colab_type": "text"
      },
      "source": [
        "## To Handle 3-D Data(seq Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxp3NuVEOLbw",
        "colab_type": "text"
      },
      "source": [
        "> auxiliary output to tune LSTM weights smoothly \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnxgUVp1c5dN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_input=Input(shape=(1,4),name=\"seq_input\")\n",
        "lstm_out=LSTM(128)(seq_input)\n",
        "auxilary_output=Dense(1,activation=\"sigmoid\",name=\"auxilary_output\")(lstm_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzJMfWQhNrVW",
        "colab_type": "text"
      },
      "source": [
        "## To Handle distance features Data\n",
        "\n",
        "> This network will take the distance feature as a input and then Concatenate that layer with the output layer of LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOvoC59Ec5dZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_seq=Input(shape=(56,),name=\"non_seq\")\n",
        "# combined with lstm output\n",
        "x=concatenate([lstm_out,non_seq])\n",
        "# now the combined data is being fed to dense layers\n",
        "dense1=Dense(30,activation='relu')(x)\n",
        "dense2=Dense(20,activation=\"relu\")(dense1)\n",
        "main_out=Dense(1,activation=\"sigmoid\",name=\"main_out\")(dense2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYuYwgZuc5df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Model(inputs=[seq_input,non_seq],outputs=[main_out,auxilary_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGDMm7Lrc5do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "             loss={\n",
        "                 'main_out':'binary_crossentropy',\n",
        "                 'auxilary_output':'binary_crossentropy'\n",
        "             },\n",
        "             loss_weights={'main_out':1, 'auxilary_output':1},\n",
        "             metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnDITwuJPID0",
        "colab_type": "text"
      },
      "source": [
        "## Defining Checkpoint to Save the Best Model While Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHqwGtIRvB1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "outputFolder = './musk_model_output'\n",
        "if not os.path.exists(outputFolder):\n",
        "    os.makedirs(outputFolder)\n",
        "filepath=outputFolder+\"/weights-{epoch:02d}-{val_main_out_acc:.4f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_main_out_acc', verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFEDOuUDPyOd",
        "colab_type": "code",
        "outputId": "27c8eca5-9685-49a6-f0cd-eaacb70e73a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "seq_input (InputLayer)          (None, 1, 4)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   (None, 128)          68096       seq_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "non_seq (InputLayer)            (None, 56)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 184)          0           lstm_8[0][0]                     \n",
            "                                                                 non_seq[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 30)           5550        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 20)           620         dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "main_out (Dense)                (None, 1)            21          dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "auxilary_output (Dense)         (None, 1)            129         lstm_8[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 74,416\n",
            "Trainable params: 74,416\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyMmTw0VQJXC",
        "colab_type": "text"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdZVyVXlc5ef",
        "colab_type": "code",
        "outputId": "448195e4-3246-4217-8534-5ba5dfa1d818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit({'seq_input':x_seq_train,\n",
        "          \"non_seq\":x_non_seq_train},\n",
        "         {\"main_out\":y_train,\"auxilary_output\":y_train},\n",
        "        validation_data=[{'seq_input': x_seq_test, 'non_seq': \n",
        "           x_non_seq_test},\n",
        "          {'main_out': y_test, 'auxilary_output': y_test}],\n",
        "         class_weight={0:0.59117384,1:3.24201474},\n",
        "         epochs=60,batch_size=32,callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5278 samples, validate on 1320 samples\n",
            "Epoch 1/60\n",
            "5278/5278 [==============================] - 4s 787us/step - loss: 0.6669 - main_out_loss: 0.2945 - auxilary_output_loss: 0.3724 - main_out_acc: 0.8763 - auxilary_output_acc: 0.8405 - val_loss: 0.5431 - val_main_out_loss: 0.1926 - val_auxilary_output_loss: 0.3505 - val_main_out_acc: 0.9273 - val_auxilary_output_acc: 0.8439\n",
            "\n",
            "Epoch 00001: val_main_out_acc improved from -inf to 0.92727, saving model to ./musk_model_output/weights-01-0.9273.h5\n",
            "Epoch 2/60\n",
            "5278/5278 [==============================] - 2s 401us/step - loss: 0.4878 - main_out_loss: 0.1526 - auxilary_output_loss: 0.3352 - main_out_acc: 0.9437 - auxilary_output_acc: 0.8621 - val_loss: 0.4639 - val_main_out_loss: 0.1284 - val_auxilary_output_loss: 0.3355 - val_main_out_acc: 0.9477 - val_auxilary_output_acc: 0.8500\n",
            "\n",
            "Epoch 00002: val_main_out_acc improved from 0.92727 to 0.94773, saving model to ./musk_model_output/weights-02-0.9477.h5\n",
            "Epoch 3/60\n",
            "5278/5278 [==============================] - 2s 403us/step - loss: 0.4442 - main_out_loss: 0.1089 - auxilary_output_loss: 0.3354 - main_out_acc: 0.9606 - auxilary_output_acc: 0.8583 - val_loss: 0.4435 - val_main_out_loss: 0.1036 - val_auxilary_output_loss: 0.3399 - val_main_out_acc: 0.9636 - val_auxilary_output_acc: 0.8455\n",
            "\n",
            "Epoch 00003: val_main_out_acc improved from 0.94773 to 0.96364, saving model to ./musk_model_output/weights-03-0.9636.h5\n",
            "Epoch 4/60\n",
            "5278/5278 [==============================] - 2s 386us/step - loss: 0.4108 - main_out_loss: 0.0824 - auxilary_output_loss: 0.3284 - main_out_acc: 0.9701 - auxilary_output_acc: 0.8645 - val_loss: 0.4328 - val_main_out_loss: 0.1008 - val_auxilary_output_loss: 0.3320 - val_main_out_acc: 0.9674 - val_auxilary_output_acc: 0.8508\n",
            "\n",
            "Epoch 00004: val_main_out_acc improved from 0.96364 to 0.96742, saving model to ./musk_model_output/weights-04-0.9674.h5\n",
            "Epoch 5/60\n",
            "5278/5278 [==============================] - 2s 395us/step - loss: 0.3928 - main_out_loss: 0.0669 - auxilary_output_loss: 0.3259 - main_out_acc: 0.9759 - auxilary_output_acc: 0.8579 - val_loss: 0.4089 - val_main_out_loss: 0.0839 - val_auxilary_output_loss: 0.3250 - val_main_out_acc: 0.9735 - val_auxilary_output_acc: 0.8583\n",
            "\n",
            "Epoch 00005: val_main_out_acc improved from 0.96742 to 0.97348, saving model to ./musk_model_output/weights-05-0.9735.h5\n",
            "Epoch 6/60\n",
            "5278/5278 [==============================] - 2s 393us/step - loss: 0.3724 - main_out_loss: 0.0517 - auxilary_output_loss: 0.3207 - main_out_acc: 0.9818 - auxilary_output_acc: 0.8649 - val_loss: 0.3949 - val_main_out_loss: 0.0695 - val_auxilary_output_loss: 0.3255 - val_main_out_acc: 0.9742 - val_auxilary_output_acc: 0.8523\n",
            "\n",
            "Epoch 00006: val_main_out_acc improved from 0.97348 to 0.97424, saving model to ./musk_model_output/weights-06-0.9742.h5\n",
            "Epoch 7/60\n",
            "5278/5278 [==============================] - 2s 393us/step - loss: 0.3644 - main_out_loss: 0.0436 - auxilary_output_loss: 0.3208 - main_out_acc: 0.9839 - auxilary_output_acc: 0.8606 - val_loss: 0.3980 - val_main_out_loss: 0.0661 - val_auxilary_output_loss: 0.3319 - val_main_out_acc: 0.9803 - val_auxilary_output_acc: 0.8576\n",
            "\n",
            "Epoch 00007: val_main_out_acc improved from 0.97424 to 0.98030, saving model to ./musk_model_output/weights-07-0.9803.h5\n",
            "Epoch 8/60\n",
            "5278/5278 [==============================] - 2s 404us/step - loss: 0.3564 - main_out_loss: 0.0357 - auxilary_output_loss: 0.3207 - main_out_acc: 0.9877 - auxilary_output_acc: 0.8604 - val_loss: 0.3959 - val_main_out_loss: 0.0597 - val_auxilary_output_loss: 0.3361 - val_main_out_acc: 0.9795 - val_auxilary_output_acc: 0.8583\n",
            "\n",
            "Epoch 00008: val_main_out_acc did not improve from 0.98030\n",
            "Epoch 9/60\n",
            "5278/5278 [==============================] - 2s 408us/step - loss: 0.3490 - main_out_loss: 0.0296 - auxilary_output_loss: 0.3194 - main_out_acc: 0.9907 - auxilary_output_acc: 0.8602 - val_loss: 0.3726 - val_main_out_loss: 0.0508 - val_auxilary_output_loss: 0.3218 - val_main_out_acc: 0.9803 - val_auxilary_output_acc: 0.8439\n",
            "\n",
            "Epoch 00009: val_main_out_acc did not improve from 0.98030\n",
            "Epoch 10/60\n",
            "5278/5278 [==============================] - 2s 412us/step - loss: 0.3415 - main_out_loss: 0.0240 - auxilary_output_loss: 0.3175 - main_out_acc: 0.9922 - auxilary_output_acc: 0.8611 - val_loss: 0.3706 - val_main_out_loss: 0.0446 - val_auxilary_output_loss: 0.3260 - val_main_out_acc: 0.9818 - val_auxilary_output_acc: 0.8470\n",
            "\n",
            "Epoch 00010: val_main_out_acc improved from 0.98030 to 0.98182, saving model to ./musk_model_output/weights-10-0.9818.h5\n",
            "Epoch 11/60\n",
            "5278/5278 [==============================] - 2s 410us/step - loss: 0.3357 - main_out_loss: 0.0192 - auxilary_output_loss: 0.3164 - main_out_acc: 0.9932 - auxilary_output_acc: 0.8606 - val_loss: 0.3664 - val_main_out_loss: 0.0431 - val_auxilary_output_loss: 0.3232 - val_main_out_acc: 0.9833 - val_auxilary_output_acc: 0.8538\n",
            "\n",
            "Epoch 00011: val_main_out_acc improved from 0.98182 to 0.98333, saving model to ./musk_model_output/weights-11-0.9833.h5\n",
            "Epoch 12/60\n",
            "5278/5278 [==============================] - 2s 414us/step - loss: 0.3276 - main_out_loss: 0.0160 - auxilary_output_loss: 0.3116 - main_out_acc: 0.9962 - auxilary_output_acc: 0.8645 - val_loss: 0.3752 - val_main_out_loss: 0.0424 - val_auxilary_output_loss: 0.3328 - val_main_out_acc: 0.9856 - val_auxilary_output_acc: 0.8538\n",
            "\n",
            "Epoch 00012: val_main_out_acc improved from 0.98333 to 0.98561, saving model to ./musk_model_output/weights-12-0.9856.h5\n",
            "Epoch 13/60\n",
            "5278/5278 [==============================] - 2s 400us/step - loss: 0.3259 - main_out_loss: 0.0150 - auxilary_output_loss: 0.3108 - main_out_acc: 0.9960 - auxilary_output_acc: 0.8628 - val_loss: 0.3769 - val_main_out_loss: 0.0478 - val_auxilary_output_loss: 0.3291 - val_main_out_acc: 0.9841 - val_auxilary_output_acc: 0.8674\n",
            "\n",
            "Epoch 00013: val_main_out_acc did not improve from 0.98561\n",
            "Epoch 14/60\n",
            "5278/5278 [==============================] - 2s 399us/step - loss: 0.3220 - main_out_loss: 0.0129 - auxilary_output_loss: 0.3091 - main_out_acc: 0.9960 - auxilary_output_acc: 0.8672 - val_loss: 0.3555 - val_main_out_loss: 0.0360 - val_auxilary_output_loss: 0.3195 - val_main_out_acc: 0.9864 - val_auxilary_output_acc: 0.8538\n",
            "\n",
            "Epoch 00014: val_main_out_acc improved from 0.98561 to 0.98636, saving model to ./musk_model_output/weights-14-0.9864.h5\n",
            "Epoch 15/60\n",
            "5278/5278 [==============================] - 2s 393us/step - loss: 0.3204 - main_out_loss: 0.0085 - auxilary_output_loss: 0.3119 - main_out_acc: 0.9983 - auxilary_output_acc: 0.8655 - val_loss: 0.3498 - val_main_out_loss: 0.0340 - val_auxilary_output_loss: 0.3158 - val_main_out_acc: 0.9886 - val_auxilary_output_acc: 0.8689\n",
            "\n",
            "Epoch 00015: val_main_out_acc improved from 0.98636 to 0.98864, saving model to ./musk_model_output/weights-15-0.9886.h5\n",
            "Epoch 16/60\n",
            "5278/5278 [==============================] - 2s 390us/step - loss: 0.3173 - main_out_loss: 0.0074 - auxilary_output_loss: 0.3099 - main_out_acc: 0.9987 - auxilary_output_acc: 0.8662 - val_loss: 0.3561 - val_main_out_loss: 0.0399 - val_auxilary_output_loss: 0.3162 - val_main_out_acc: 0.9871 - val_auxilary_output_acc: 0.8409\n",
            "\n",
            "Epoch 00016: val_main_out_acc did not improve from 0.98864\n",
            "Epoch 17/60\n",
            "5278/5278 [==============================] - 2s 397us/step - loss: 0.3188 - main_out_loss: 0.0071 - auxilary_output_loss: 0.3118 - main_out_acc: 0.9991 - auxilary_output_acc: 0.8611 - val_loss: 0.3507 - val_main_out_loss: 0.0374 - val_auxilary_output_loss: 0.3133 - val_main_out_acc: 0.9848 - val_auxilary_output_acc: 0.8538\n",
            "\n",
            "Epoch 00017: val_main_out_acc did not improve from 0.98864\n",
            "Epoch 18/60\n",
            "5278/5278 [==============================] - 2s 394us/step - loss: 0.3136 - main_out_loss: 0.0052 - auxilary_output_loss: 0.3084 - main_out_acc: 0.9989 - auxilary_output_acc: 0.8664 - val_loss: 0.3462 - val_main_out_loss: 0.0341 - val_auxilary_output_loss: 0.3121 - val_main_out_acc: 0.9871 - val_auxilary_output_acc: 0.8424\n",
            "\n",
            "Epoch 00018: val_main_out_acc did not improve from 0.98864\n",
            "Epoch 19/60\n",
            "5278/5278 [==============================] - 2s 391us/step - loss: 0.3151 - main_out_loss: 0.0050 - auxilary_output_loss: 0.3101 - main_out_acc: 0.9987 - auxilary_output_acc: 0.8672 - val_loss: 0.3705 - val_main_out_loss: 0.0468 - val_auxilary_output_loss: 0.3237 - val_main_out_acc: 0.9856 - val_auxilary_output_acc: 0.8485\n",
            "\n",
            "Epoch 00019: val_main_out_acc did not improve from 0.98864\n",
            "Epoch 20/60\n",
            "5278/5278 [==============================] - 2s 399us/step - loss: 0.3111 - main_out_loss: 0.0045 - auxilary_output_loss: 0.3066 - main_out_acc: 0.9989 - auxilary_output_acc: 0.8691 - val_loss: 0.3429 - val_main_out_loss: 0.0319 - val_auxilary_output_loss: 0.3110 - val_main_out_acc: 0.9864 - val_auxilary_output_acc: 0.8689\n",
            "\n",
            "Epoch 00020: val_main_out_acc did not improve from 0.98864\n",
            "Epoch 21/60\n",
            "5278/5278 [==============================] - 2s 391us/step - loss: 0.3103 - main_out_loss: 0.0040 - auxilary_output_loss: 0.3062 - main_out_acc: 0.9991 - auxilary_output_acc: 0.8660 - val_loss: 0.3558 - val_main_out_loss: 0.0403 - val_auxilary_output_loss: 0.3155 - val_main_out_acc: 0.9902 - val_auxilary_output_acc: 0.8417\n",
            "\n",
            "Epoch 00021: val_main_out_acc improved from 0.98864 to 0.99015, saving model to ./musk_model_output/weights-21-0.9902.h5\n",
            "Epoch 22/60\n",
            "5278/5278 [==============================] - 2s 399us/step - loss: 0.3090 - main_out_loss: 0.0032 - auxilary_output_loss: 0.3058 - main_out_acc: 0.9996 - auxilary_output_acc: 0.8651 - val_loss: 0.3467 - val_main_out_loss: 0.0374 - val_auxilary_output_loss: 0.3093 - val_main_out_acc: 0.9886 - val_auxilary_output_acc: 0.8485\n",
            "\n",
            "Epoch 00022: val_main_out_acc did not improve from 0.99015\n",
            "Epoch 23/60\n",
            "5278/5278 [==============================] - 2s 395us/step - loss: 0.3098 - main_out_loss: 0.0019 - auxilary_output_loss: 0.3080 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8643 - val_loss: 0.3426 - val_main_out_loss: 0.0347 - val_auxilary_output_loss: 0.3079 - val_main_out_acc: 0.9902 - val_auxilary_output_acc: 0.8447\n",
            "\n",
            "Epoch 00023: val_main_out_acc did not improve from 0.99015\n",
            "Epoch 24/60\n",
            "5278/5278 [==============================] - 2s 394us/step - loss: 0.3032 - main_out_loss: 0.0012 - auxilary_output_loss: 0.3020 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8679 - val_loss: 0.3525 - val_main_out_loss: 0.0330 - val_auxilary_output_loss: 0.3195 - val_main_out_acc: 0.9894 - val_auxilary_output_acc: 0.8644\n",
            "\n",
            "Epoch 00024: val_main_out_acc did not improve from 0.99015\n",
            "Epoch 25/60\n",
            "5278/5278 [==============================] - 2s 392us/step - loss: 0.3014 - main_out_loss: 0.0014 - auxilary_output_loss: 0.2999 - main_out_acc: 0.9996 - auxilary_output_acc: 0.8679 - val_loss: 0.3461 - val_main_out_loss: 0.0341 - val_auxilary_output_loss: 0.3120 - val_main_out_acc: 0.9879 - val_auxilary_output_acc: 0.8485\n",
            "\n",
            "Epoch 00025: val_main_out_acc did not improve from 0.99015\n",
            "Epoch 26/60\n",
            "5278/5278 [==============================] - 2s 393us/step - loss: 0.3031 - main_out_loss: 0.0025 - auxilary_output_loss: 0.3006 - main_out_acc: 0.9996 - auxilary_output_acc: 0.8664 - val_loss: 0.3642 - val_main_out_loss: 0.0466 - val_auxilary_output_loss: 0.3176 - val_main_out_acc: 0.9864 - val_auxilary_output_acc: 0.8417\n",
            "\n",
            "Epoch 00026: val_main_out_acc did not improve from 0.99015\n",
            "Epoch 27/60\n",
            "5278/5278 [==============================] - 2s 393us/step - loss: 0.3093 - main_out_loss: 0.0032 - auxilary_output_loss: 0.3060 - main_out_acc: 0.9989 - auxilary_output_acc: 0.8691 - val_loss: 0.3339 - val_main_out_loss: 0.0266 - val_auxilary_output_loss: 0.3073 - val_main_out_acc: 0.9894 - val_auxilary_output_acc: 0.8553\n",
            "\n",
            "Epoch 00027: val_main_out_acc did not improve from 0.99015\n",
            "Epoch 28/60\n",
            "5278/5278 [==============================] - 2s 401us/step - loss: 0.3068 - main_out_loss: 0.0052 - auxilary_output_loss: 0.3016 - main_out_acc: 0.9987 - auxilary_output_acc: 0.8732 - val_loss: 0.3419 - val_main_out_loss: 0.0385 - val_auxilary_output_loss: 0.3033 - val_main_out_acc: 0.9848 - val_auxilary_output_acc: 0.8583\n",
            "\n",
            "Epoch 00028: val_main_out_acc did not improve from 0.99015\n",
            "Epoch 29/60\n",
            "5278/5278 [==============================] - 2s 398us/step - loss: 0.3021 - main_out_loss: 0.0022 - auxilary_output_loss: 0.3000 - main_out_acc: 0.9992 - auxilary_output_acc: 0.8736 - val_loss: 0.3632 - val_main_out_loss: 0.0472 - val_auxilary_output_loss: 0.3159 - val_main_out_acc: 0.9871 - val_auxilary_output_acc: 0.8576\n",
            "\n",
            "Epoch 00029: val_main_out_acc did not improve from 0.99015\n",
            "Epoch 30/60\n",
            "5278/5278 [==============================] - 2s 391us/step - loss: 0.3088 - main_out_loss: 0.0086 - auxilary_output_loss: 0.3002 - main_out_acc: 0.9977 - auxilary_output_acc: 0.8657 - val_loss: 0.3477 - val_main_out_loss: 0.0389 - val_auxilary_output_loss: 0.3088 - val_main_out_acc: 0.9894 - val_auxilary_output_acc: 0.8424\n",
            "\n",
            "Epoch 00030: val_main_out_acc did not improve from 0.99015\n",
            "Epoch 31/60\n",
            "5278/5278 [==============================] - 2s 395us/step - loss: 0.3003 - main_out_loss: 0.0041 - auxilary_output_loss: 0.2962 - main_out_acc: 0.9994 - auxilary_output_acc: 0.8789 - val_loss: 0.3560 - val_main_out_loss: 0.0569 - val_auxilary_output_loss: 0.2991 - val_main_out_acc: 0.9833 - val_auxilary_output_acc: 0.8788\n",
            "\n",
            "Epoch 00031: val_main_out_acc did not improve from 0.99015\n",
            "Epoch 32/60\n",
            "5278/5278 [==============================] - 2s 391us/step - loss: 0.3059 - main_out_loss: 0.0042 - auxilary_output_loss: 0.3016 - main_out_acc: 0.9991 - auxilary_output_acc: 0.8700 - val_loss: 0.3348 - val_main_out_loss: 0.0261 - val_auxilary_output_loss: 0.3087 - val_main_out_acc: 0.9924 - val_auxilary_output_acc: 0.8523\n",
            "\n",
            "Epoch 00032: val_main_out_acc improved from 0.99015 to 0.99242, saving model to ./musk_model_output/weights-32-0.9924.h5\n",
            "Epoch 33/60\n",
            "5278/5278 [==============================] - 2s 401us/step - loss: 0.2971 - main_out_loss: 6.3478e-04 - auxilary_output_loss: 0.2964 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8736 - val_loss: 0.3203 - val_main_out_loss: 0.0237 - val_auxilary_output_loss: 0.2966 - val_main_out_acc: 0.9932 - val_auxilary_output_acc: 0.8689\n",
            "\n",
            "Epoch 00033: val_main_out_acc improved from 0.99242 to 0.99318, saving model to ./musk_model_output/weights-33-0.9932.h5\n",
            "Epoch 34/60\n",
            "5278/5278 [==============================] - 2s 397us/step - loss: 0.2972 - main_out_loss: 4.1472e-04 - auxilary_output_loss: 0.2968 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8717 - val_loss: 0.3303 - val_main_out_loss: 0.0236 - val_auxilary_output_loss: 0.3067 - val_main_out_acc: 0.9909 - val_auxilary_output_acc: 0.8492\n",
            "\n",
            "Epoch 00034: val_main_out_acc did not improve from 0.99318\n",
            "Epoch 35/60\n",
            "5278/5278 [==============================] - 2s 387us/step - loss: 0.3008 - main_out_loss: 6.0501e-04 - auxilary_output_loss: 0.3002 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8642 - val_loss: 0.3304 - val_main_out_loss: 0.0264 - val_auxilary_output_loss: 0.3040 - val_main_out_acc: 0.9917 - val_auxilary_output_acc: 0.8659\n",
            "\n",
            "Epoch 00035: val_main_out_acc did not improve from 0.99318\n",
            "Epoch 36/60\n",
            "5278/5278 [==============================] - 2s 392us/step - loss: 0.2953 - main_out_loss: 7.2946e-04 - auxilary_output_loss: 0.2946 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8700 - val_loss: 0.3226 - val_main_out_loss: 0.0201 - val_auxilary_output_loss: 0.3025 - val_main_out_acc: 0.9932 - val_auxilary_output_acc: 0.8644\n",
            "\n",
            "Epoch 00036: val_main_out_acc did not improve from 0.99318\n",
            "Epoch 37/60\n",
            "5278/5278 [==============================] - 2s 387us/step - loss: 0.2942 - main_out_loss: 3.2642e-04 - auxilary_output_loss: 0.2939 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8765 - val_loss: 0.3288 - val_main_out_loss: 0.0284 - val_auxilary_output_loss: 0.3004 - val_main_out_acc: 0.9917 - val_auxilary_output_acc: 0.8697\n",
            "\n",
            "Epoch 00037: val_main_out_acc did not improve from 0.99318\n",
            "Epoch 38/60\n",
            "5278/5278 [==============================] - 2s 389us/step - loss: 0.2954 - main_out_loss: 2.3472e-04 - auxilary_output_loss: 0.2952 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8750 - val_loss: 0.3235 - val_main_out_loss: 0.0227 - val_auxilary_output_loss: 0.3009 - val_main_out_acc: 0.9932 - val_auxilary_output_acc: 0.8500\n",
            "\n",
            "Epoch 00038: val_main_out_acc did not improve from 0.99318\n",
            "Epoch 39/60\n",
            "5278/5278 [==============================] - 2s 395us/step - loss: 0.2924 - main_out_loss: 2.9938e-04 - auxilary_output_loss: 0.2921 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8740 - val_loss: 0.3228 - val_main_out_loss: 0.0279 - val_auxilary_output_loss: 0.2949 - val_main_out_acc: 0.9924 - val_auxilary_output_acc: 0.8652\n",
            "\n",
            "Epoch 00039: val_main_out_acc did not improve from 0.99318\n",
            "Epoch 40/60\n",
            "5278/5278 [==============================] - 2s 394us/step - loss: 0.2905 - main_out_loss: 2.3387e-04 - auxilary_output_loss: 0.2903 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8734 - val_loss: 0.3203 - val_main_out_loss: 0.0230 - val_auxilary_output_loss: 0.2973 - val_main_out_acc: 0.9917 - val_auxilary_output_acc: 0.8485\n",
            "\n",
            "Epoch 00040: val_main_out_acc did not improve from 0.99318\n",
            "Epoch 41/60\n",
            "5278/5278 [==============================] - 2s 393us/step - loss: 0.2943 - main_out_loss: 2.0398e-04 - auxilary_output_loss: 0.2941 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8755 - val_loss: 0.3187 - val_main_out_loss: 0.0248 - val_auxilary_output_loss: 0.2939 - val_main_out_acc: 0.9917 - val_auxilary_output_acc: 0.8667\n",
            "\n",
            "Epoch 00041: val_main_out_acc did not improve from 0.99318\n",
            "Epoch 42/60\n",
            "5278/5278 [==============================] - 2s 392us/step - loss: 0.2906 - main_out_loss: 1.6842e-04 - auxilary_output_loss: 0.2904 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8746 - val_loss: 0.3259 - val_main_out_loss: 0.0260 - val_auxilary_output_loss: 0.2999 - val_main_out_acc: 0.9924 - val_auxilary_output_acc: 0.8652\n",
            "\n",
            "Epoch 00042: val_main_out_acc did not improve from 0.99318\n",
            "Epoch 43/60\n",
            "5278/5278 [==============================] - 2s 399us/step - loss: 0.2927 - main_out_loss: 1.4485e-04 - auxilary_output_loss: 0.2926 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8814 - val_loss: 0.3185 - val_main_out_loss: 0.0235 - val_auxilary_output_loss: 0.2950 - val_main_out_acc: 0.9939 - val_auxilary_output_acc: 0.8629\n",
            "\n",
            "Epoch 00043: val_main_out_acc improved from 0.99318 to 0.99394, saving model to ./musk_model_output/weights-43-0.9939.h5\n",
            "Epoch 44/60\n",
            "5278/5278 [==============================] - 2s 390us/step - loss: 0.2914 - main_out_loss: 1.2596e-04 - auxilary_output_loss: 0.2913 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8799 - val_loss: 0.3239 - val_main_out_loss: 0.0240 - val_auxilary_output_loss: 0.2999 - val_main_out_acc: 0.9947 - val_auxilary_output_acc: 0.8682\n",
            "\n",
            "Epoch 00044: val_main_out_acc improved from 0.99394 to 0.99470, saving model to ./musk_model_output/weights-44-0.9947.h5\n",
            "Epoch 45/60\n",
            "5278/5278 [==============================] - 2s 383us/step - loss: 0.2906 - main_out_loss: 1.3245e-04 - auxilary_output_loss: 0.2905 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8776 - val_loss: 0.3214 - val_main_out_loss: 0.0224 - val_auxilary_output_loss: 0.2990 - val_main_out_acc: 0.9955 - val_auxilary_output_acc: 0.8652\n",
            "\n",
            "Epoch 00045: val_main_out_acc improved from 0.99470 to 0.99545, saving model to ./musk_model_output/weights-45-0.9955.h5\n",
            "Epoch 46/60\n",
            "5278/5278 [==============================] - 2s 387us/step - loss: 0.2914 - main_out_loss: 1.4017e-04 - auxilary_output_loss: 0.2912 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8801 - val_loss: 0.3160 - val_main_out_loss: 0.0233 - val_auxilary_output_loss: 0.2927 - val_main_out_acc: 0.9924 - val_auxilary_output_acc: 0.8636\n",
            "\n",
            "Epoch 00046: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 47/60\n",
            "5278/5278 [==============================] - 2s 388us/step - loss: 0.3034 - main_out_loss: 0.0153 - auxilary_output_loss: 0.2880 - main_out_acc: 0.9955 - auxilary_output_acc: 0.8839 - val_loss: 0.4161 - val_main_out_loss: 0.1147 - val_auxilary_output_loss: 0.3014 - val_main_out_acc: 0.9750 - val_auxilary_output_acc: 0.8750\n",
            "\n",
            "Epoch 00047: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 48/60\n",
            "5278/5278 [==============================] - 2s 387us/step - loss: 0.3034 - main_out_loss: 0.0104 - auxilary_output_loss: 0.2930 - main_out_acc: 0.9962 - auxilary_output_acc: 0.8816 - val_loss: 0.3449 - val_main_out_loss: 0.0488 - val_auxilary_output_loss: 0.2961 - val_main_out_acc: 0.9864 - val_auxilary_output_acc: 0.8765\n",
            "\n",
            "Epoch 00048: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 49/60\n",
            "5278/5278 [==============================] - 2s 397us/step - loss: 0.2926 - main_out_loss: 0.0010 - auxilary_output_loss: 0.2916 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8812 - val_loss: 0.3235 - val_main_out_loss: 0.0347 - val_auxilary_output_loss: 0.2888 - val_main_out_acc: 0.9886 - val_auxilary_output_acc: 0.8795\n",
            "\n",
            "Epoch 00049: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 50/60\n",
            "5278/5278 [==============================] - 2s 394us/step - loss: 0.2931 - main_out_loss: 4.5758e-04 - auxilary_output_loss: 0.2926 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8835 - val_loss: 0.3286 - val_main_out_loss: 0.0287 - val_auxilary_output_loss: 0.3000 - val_main_out_acc: 0.9902 - val_auxilary_output_acc: 0.8576\n",
            "\n",
            "Epoch 00050: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 51/60\n",
            "5278/5278 [==============================] - 2s 392us/step - loss: 0.2901 - main_out_loss: 2.6488e-04 - auxilary_output_loss: 0.2898 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8869 - val_loss: 0.3224 - val_main_out_loss: 0.0301 - val_auxilary_output_loss: 0.2923 - val_main_out_acc: 0.9917 - val_auxilary_output_acc: 0.8788\n",
            "\n",
            "Epoch 00051: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 52/60\n",
            "5278/5278 [==============================] - 2s 394us/step - loss: 0.2931 - main_out_loss: 2.8287e-04 - auxilary_output_loss: 0.2929 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8801 - val_loss: 0.3377 - val_main_out_loss: 0.0309 - val_auxilary_output_loss: 0.3067 - val_main_out_acc: 0.9909 - val_auxilary_output_acc: 0.8538\n",
            "\n",
            "Epoch 00052: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 53/60\n",
            "5278/5278 [==============================] - 2s 389us/step - loss: 0.2917 - main_out_loss: 1.8701e-04 - auxilary_output_loss: 0.2915 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8837 - val_loss: 0.3187 - val_main_out_loss: 0.0262 - val_auxilary_output_loss: 0.2924 - val_main_out_acc: 0.9932 - val_auxilary_output_acc: 0.8773\n",
            "\n",
            "Epoch 00053: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 54/60\n",
            "5278/5278 [==============================] - 2s 398us/step - loss: 0.2913 - main_out_loss: 1.6972e-04 - auxilary_output_loss: 0.2911 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8774 - val_loss: 0.3264 - val_main_out_loss: 0.0281 - val_auxilary_output_loss: 0.2983 - val_main_out_acc: 0.9917 - val_auxilary_output_acc: 0.8636\n",
            "\n",
            "Epoch 00054: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 55/60\n",
            "5278/5278 [==============================] - 2s 397us/step - loss: 0.2895 - main_out_loss: 1.8751e-04 - auxilary_output_loss: 0.2893 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8818 - val_loss: 0.3320 - val_main_out_loss: 0.0244 - val_auxilary_output_loss: 0.3075 - val_main_out_acc: 0.9932 - val_auxilary_output_acc: 0.8591\n",
            "\n",
            "Epoch 00055: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 56/60\n",
            "5278/5278 [==============================] - 2s 389us/step - loss: 0.2915 - main_out_loss: 1.3129e-04 - auxilary_output_loss: 0.2914 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8804 - val_loss: 0.3182 - val_main_out_loss: 0.0250 - val_auxilary_output_loss: 0.2931 - val_main_out_acc: 0.9932 - val_auxilary_output_acc: 0.8705\n",
            "\n",
            "Epoch 00056: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 57/60\n",
            "5278/5278 [==============================] - 2s 397us/step - loss: 0.2896 - main_out_loss: 1.1062e-04 - auxilary_output_loss: 0.2895 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8829 - val_loss: 0.3189 - val_main_out_loss: 0.0236 - val_auxilary_output_loss: 0.2953 - val_main_out_acc: 0.9917 - val_auxilary_output_acc: 0.8742\n",
            "\n",
            "Epoch 00057: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 58/60\n",
            "5278/5278 [==============================] - 2s 396us/step - loss: 0.2907 - main_out_loss: 1.2166e-04 - auxilary_output_loss: 0.2906 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8867 - val_loss: 0.3220 - val_main_out_loss: 0.0283 - val_auxilary_output_loss: 0.2937 - val_main_out_acc: 0.9924 - val_auxilary_output_acc: 0.8841\n",
            "\n",
            "Epoch 00058: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 59/60\n",
            "5278/5278 [==============================] - 2s 400us/step - loss: 0.2875 - main_out_loss: 1.0796e-04 - auxilary_output_loss: 0.2874 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8829 - val_loss: 0.3246 - val_main_out_loss: 0.0276 - val_auxilary_output_loss: 0.2970 - val_main_out_acc: 0.9917 - val_auxilary_output_acc: 0.8644\n",
            "\n",
            "Epoch 00059: val_main_out_acc did not improve from 0.99545\n",
            "Epoch 60/60\n",
            "5278/5278 [==============================] - 2s 395us/step - loss: 0.2895 - main_out_loss: 7.8131e-05 - auxilary_output_loss: 0.2895 - main_out_acc: 1.0000 - auxilary_output_acc: 0.8840 - val_loss: 0.3165 - val_main_out_loss: 0.0279 - val_auxilary_output_loss: 0.2887 - val_main_out_acc: 0.9917 - val_auxilary_output_acc: 0.8818\n",
            "\n",
            "Epoch 00060: val_main_out_acc did not improve from 0.99545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lkoQzCfS0zJ",
        "colab_type": "code",
        "outputId": "f9af51bc-1abc-40a5-a7a4-526416b88fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_main_out_loss', 'val_auxilary_output_loss', 'val_main_out_acc', 'val_auxilary_output_acc', 'loss', 'main_out_loss', 'auxilary_output_loss', 'main_out_acc', 'auxilary_output_acc'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY0ZJFgBWmVa",
        "colab_type": "code",
        "outputId": "f4f49c59-7cbc-4195-a1bd-0ba6585c52f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history.history['main_out_acc'])\n",
        "plt.plot(history.history['val_main_out_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['main_out_loss'])\n",
        "plt.plot(history.history['val_main_out_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7y3Vq4FYjQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwhhjTET/H7Xc04QkUTkKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhnlyAG1XzqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "check=load_model(\"/content/musk_model_output/weights-45-0.9955.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAwuJhQeY2Ic",
        "colab_type": "code",
        "outputId": "5d98b00a-092a-48db-9a27-8bbe9af63d38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "check.summary()"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "seq_input (InputLayer)          (None, 1, 4)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   (None, 128)          68096       seq_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "non_seq (InputLayer)            (None, 56)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 184)          0           lstm_8[0][0]                     \n",
            "                                                                 non_seq[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 30)           5550        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 20)           620         dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "main_out (Dense)                (None, 1)            21          dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "auxilary_output (Dense)         (None, 1)            129         lstm_8[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 74,416\n",
            "Trainable params: 74,416\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-iTug-4mK8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score,recall_score,f1_score,log_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTdIXUObZcuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=check.predict(x={'seq_input': x_seq_test, 'non_seq': \n",
        "          x_non_seq_test})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjdZILsutpZs",
        "colab_type": "text"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsxOZL8Nu3MU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbfd3ae5-090a-4e86-ce44-907cedccc768"
      },
      "source": [
        "evaluate=check.evaluate(x={'seq_input': x_seq_test, 'non_seq': \n",
        "          x_non_seq_test},y={'main_out': y_test, 'auxilary_output': \n",
        "          y_test})"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1320/1320 [==============================] - 1s 872us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHcxkl7tvSfg",
        "colab_type": "text"
      },
      "source": [
        ">evaluate[0]----val_loss\n",
        "\n",
        ">evaluate[1]----val_main_out_loss (Main Loss)\n",
        "\n",
        ">evaluate[2]----val_auxilary_output_loss\n",
        "\n",
        ">evaluate[3]----val_main_out_acc\n",
        "\n",
        ">evaluate[3]----val_auxilary_output_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAphJ4rjwnOX",
        "colab_type": "text"
      },
      "source": [
        "## The loss is around 0.022 for **main_out** layer output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSNP2jP3vkn9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91f62c86-57d0-4180-c1d2-be2699608558"
      },
      "source": [
        "evaluate[1]"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022360007547577727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY0S1FDVnmIu",
        "colab_type": "text"
      },
      "source": [
        "### The  Accuracy is 99.5% from ***main_out***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2taMbulic63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efeb9429-79f5-409f-f666-dd21fbbab7a0"
      },
      "source": [
        "accuracy_score(y_test,pred[0].round()) *100"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99.54545454545455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F_CtF_PrxYH",
        "colab_type": "text"
      },
      "source": [
        "### precision_score is 99% from ***main_out***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1G_9djPqoqZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de137ab5-793e-4a58-b506-2ae71e6f7677"
      },
      "source": [
        "precision_score(y_test,pred[0].round())*100"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99.00497512437812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayU2RZ-osAHp",
        "colab_type": "text"
      },
      "source": [
        "### recall_score is 98% from ***main_out***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eavy8nwwq8kS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8a56c10-158a-4705-9287-01591885ffbe"
      },
      "source": [
        "recall_score(y_test,pred[0].round())*100"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.0295566502463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq3u4ER8sGBg",
        "colab_type": "text"
      },
      "source": [
        "### f1_score is 98.5% from ***main_out***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnqNBvIZrDvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc1fec86-404c-4c88-f22f-bcc57b6c2fc4"
      },
      "source": [
        "f1_score(y_test,pred[0].round())*100"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.51485148514853"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    }
  ]
}